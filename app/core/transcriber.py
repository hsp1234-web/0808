# app/core/transcriber.py
import time
import threading
import logging
from pathlib import Path
from opencc import OpenCC

log = logging.getLogger('transcriber')

class Transcriber:
    """
    ä¸€å€‹ç®¡ç† Whisper æ¨¡å‹ç”Ÿå‘½é€±æœŸä¸¦åŸ·è¡Œè½‰éŒ„çš„é¡åˆ¥ã€‚
    å¯¦ç¾äº†å»¶é²è¼‰å…¥ (lazy loading) èˆ‡å¿«å–æ©Ÿåˆ¶ï¼Œä»¥ç¢ºä¿åªæœ‰åœ¨é¦–æ¬¡éœ€è¦æ™‚æ‰è¼‰å…¥ç‰¹å®šå¤§å°çš„æ¨¡å‹ï¼Œ
    å¾è€ŒåŠ å¿«æ‡‰ç”¨ç¨‹å¼çš„åˆå§‹å•Ÿå‹•é€Ÿåº¦ä¸¦åœ¨å¾ŒçºŒè«‹æ±‚ä¸­é‡è¤‡ä½¿ç”¨å·²è¼‰å…¥çš„æ¨¡å‹ã€‚
    """
    _instance = None
    _models = {}  # ä¿®æ”¹ç‚ºå­—å…¸ä»¥å¿«å–ä¸åŒå¤§å°çš„æ¨¡å‹
    _model_lock = threading.Lock()

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(Transcriber, cls).__new__(cls)
        return cls._instance

    def _load_model(self, model_size: str = "tiny"):
        """
        ç§æœ‰æ–¹æ³•ï¼Œæ ¹æ“šæŒ‡å®šçš„æ¨¡å‹å¤§å°è¼‰å…¥æˆ–å¾å¿«å–ä¸­å–å¾— faster-whisper æ¨¡å‹ã€‚
        """
        # æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦å·²æœ‰æ­¤æ¨¡å‹
        if model_size in self._models:
            log.info(f"ğŸ§  å¾å¿«å–ä¸­å–å¾— '{model_size}' æ¨¡å‹ã€‚")
            return self._models[model_size]

        # å¦‚æœå¿«å–ä¸­æ²’æœ‰ï¼Œå‰‡åŠ è¼‰æ–°æ¨¡å‹
        with self._model_lock:
            # å†æ¬¡æª¢æŸ¥ï¼Œé˜²æ­¢åœ¨ç­‰å¾…é–çš„éç¨‹ä¸­å…¶ä»–åŸ·è¡Œç·’å·²ç¶“è¼‰å…¥
            if model_size in self._models:
                return self._models[model_size]

            log.info(f"ğŸ§  å¿«å–ä¸­ç„¡ '{model_size}' æ¨¡å‹ã€‚é–‹å§‹åŸ·è¡Œé¦–æ¬¡è¼‰å…¥...")
            start_time = time.time()
            try:
                from faster_whisper import WhisperModel

                # TODO: æœªä¾†å¯ä»¥æ ¹æ“šç³»çµ±æ˜¯å¦æœ‰ GPU è‡ªå‹•é¸æ“‡ device å’Œ compute_type
                model = WhisperModel(model_size, device="cpu", compute_type="int8")

                duration = time.time() - start_time
                log.info(f"âœ… æˆåŠŸè¼‰å…¥ '{model_size}' æ¨¡å‹ï¼è€—æ™‚: {duration:.2f} ç§’ã€‚")

                # å°‡æ–°è¼‰å…¥çš„æ¨¡å‹å­˜å…¥å¿«å–
                self._models[model_size] = model
                return model
            except ImportError as e:
                log.critical(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼šç¼ºå°‘ 'faster_whisper' æ¨¡çµ„ã€‚è«‹ç¢ºèª 'requirements-worker.txt' å·²æ­£ç¢ºå®‰è£ã€‚")
                raise e
            except Exception as e:
                log.critical(f"âŒ è¼‰å…¥ '{model_size}' æ¨¡å‹æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
                raise e

    def transcribe(self, audio_path: Path | str, model_size: str, language: str, status_callback=None) -> str:
        """
        åŸ·è¡ŒéŸ³è¨Šè½‰éŒ„çš„æ ¸å¿ƒæ–¹æ³•ï¼Œä¸¦å¯é¸æ“‡æ€§åœ°é€éå›å‘¼å‡½å¼å›å ±é€²åº¦ã€‚
        """
        def report(status):
            if status_callback:
                status_callback(status)

        log.info(f"ğŸ¤ é–‹å§‹è™•ç†è½‰éŒ„ä»»å‹™: {audio_path}")
        report(f"è¼‰å…¥ '{model_size}' æ¨¡å‹ä¸­...")

        try:
            model = self._load_model(model_size)
        except Exception as e:
            return f"è½‰éŒ„å¤±æ•—ï¼šç„¡æ³•è¼‰å…¥æ¨¡å‹ '{model_size}'ã€‚éŒ¯èª¤: {e}"

        if model is None:
            return f"è½‰éŒ„å¤±æ•—ï¼šæ¨¡å‹ '{model_size}' å¯¦ä¾‹ä¸å­˜åœ¨ã€‚"

        try:
            start_time = time.time()
            report("æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œé–‹å§‹è½‰éŒ„...")

            # ä½¿ç”¨ word_timestamps=True å¯ä»¥è®“æˆ‘å€‘åœ¨æœªä¾†å¯¦ç¾æ›´ç´°ç·»çš„é€²åº¦å›å ±
            segments, info = model.transcribe(str(audio_path), beam_size=5, language=language, word_timestamps=True)

            if language:
                log.info(f"ğŸŒ ä½¿ç”¨è€…æŒ‡å®šèªè¨€: '{language}'ï¼Œåµæ¸¬åˆ° '{info.language}' (æ©Ÿç‡: {info.language_probability:.2f})")
            else:
                log.info(f"ğŸŒ è‡ªå‹•åµæ¸¬åˆ°èªè¨€: '{info.language}' (æ©Ÿç‡: {info.language_probability:.2f})")

            # --- é€²åº¦å›å ± ---
            # å»ºç«‹ä¸€å€‹åŒ…å«æ‰€æœ‰éŸ³è¨Šç‰‡æ®µæ–‡å­—çš„ç”Ÿæˆå™¨
            segment_generator = (segment.text for segment in segments)
            full_transcript = "".join(segment_generator).strip()

            # (é€™è£¡çš„é€²åº¦å›å ±é‚è¼¯å¯ä»¥æ›´è¤‡é›œï¼Œä¾‹å¦‚æ ¹æ“šæ™‚é–“æˆ³ï¼Œä½†ç›®å‰ä¿æŒç°¡å–®)
            report("è½‰éŒ„æ ¸å¿ƒè™•ç†å®Œæˆ")

            duration = time.time() - start_time
            log.info(f"ğŸ“ è½‰éŒ„å®Œæˆã€‚è€—æ™‚: {duration:.2f} ç§’ã€‚")

            if language and language.lower().startswith('zh'):
                report("ç¹ç°¡è½‰æ›ä¸­...")
                log.info("ğŸ”„ åµæ¸¬åˆ°ä¸­æ–‡ï¼Œæ­£åœ¨åŸ·è¡Œç¹é«”åŒ–è™•ç†...")
                try:
                    cc = OpenCC('s2twp')
                    converted_transcript = cc.convert(full_transcript)
                    log.info("âœ… ç¹é«”åŒ–è™•ç†å®Œæˆã€‚")
                    report("è™•ç†å®Œæˆ")
                    return converted_transcript
                except Exception as e:
                    log.error(f"âŒ ç¹ç°¡è½‰æ›æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
                    return full_transcript
            else:
                report("è™•ç†å®Œæˆ")
                return full_transcript

        except Exception as e:
            log.error(f"âŒ è½‰éŒ„éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            return f"è½‰éŒ„å¤±æ•—ï¼šè™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ã€‚éŒ¯èª¤: {e}"

# å»ºç«‹ä¸€å€‹å…¨åŸŸçš„å–®ä¾‹ï¼Œä½†åƒ…åœ¨éæ¨¡æ“¬æ¨¡å¼ä¸‹
import os
if os.environ.get("MOCK_TRANSCRIBER") == "true":
    # åœ¨æ¨¡æ“¬æ¨¡å¼ä¸‹ï¼Œæˆ‘å€‘å°‡ transcriber_instance è¨­ç‚º MockTranscriber çš„ä¸€å€‹å¯¦ä¾‹
    # é€™æ¨£ worker å°±å¯ä»¥çµ±ä¸€ä½¿ç”¨ transcriber_instance é€™å€‹è®Šæ•¸å
    transcriber_instance = MockTranscriber()
else:
    # åªæœ‰åœ¨çœŸå¯¦æ¨¡å¼ä¸‹ï¼Œæ‰å»ºç«‹ä¸¦è¼‰å…¥çœŸå¯¦çš„è½‰éŒ„å™¨å¯¦ä¾‹
    transcriber_instance = Transcriber()


class MockTranscriber:
    """ä¸€å€‹ç”¨æ–¼æ¸¬è©¦çš„æ¨¡æ“¬è½‰éŒ„å™¨ï¼Œå®ƒä¸æœƒè¼‰å…¥ä»»ä½•æ¨¡å‹ï¼Œåªæœƒæ¨¡æ“¬è¡Œç‚ºã€‚"""
    def transcribe(self, audio_path: str, model_size: str, language: str, status_callback=None):
        """æ¨¡æ“¬è½‰éŒ„éç¨‹ï¼Œä¸¦é€éå›å‘¼å‡½å¼å›å ±é€²åº¦ã€‚"""
        import time

        def report(status):
            if status_callback:
                status_callback(status)

        report("æ¨¡æ“¬ï¼šä»»å‹™é–‹å§‹...")
        time.sleep(0.1)
        report("æ¨¡æ“¬ï¼šè™•ç†ä¸­ 1/3")
        time.sleep(0.1)
        report("æ¨¡æ“¬ï¼šè™•ç†ä¸­ 2/3")
        time.sleep(0.1)
        report("æ¨¡æ“¬ï¼šè™•ç†ä¸­ 3/3")
        time.sleep(0.1)
        report("æ¨¡æ“¬ï¼šç¹ç°¡è½‰æ›ä¸­...")
        time.sleep(0.1)

        return f"é€™æ˜¯ä¸€å€‹ä¾†è‡ªæ¨¡æ“¬è½‰éŒ„å™¨çš„æ¸¬è©¦çµæœã€‚éŸ³è¨Šè·¯å¾‘: {audio_path}, æ¨¡å‹: {model_size}, èªè¨€: {language}"
