# tools/transcriber.py

# --- å¯ä¾› bake_envs.py è§£æçš„ä¾è³´å®šç¾© ---
# ä½¿ç”¨ ast.literal_eval å®‰å…¨è§£æ
DEPENDENCIES = {
    # 'å¥—ä»¶å': 'åœ¨ pip install ä¸­ä½¿ç”¨çš„åç¨±'
    'faster-whisper': 'faster-whisper',
    'opencc': 'opencc-python-reimplemented'
}

import time
import logging
import argparse
from pathlib import Path
from opencc import OpenCC

# --- æ—¥èªŒè¨­å®š ---
# è¨­å®šä¸€å€‹åŸºæœ¬çš„æ—¥èªŒè¨˜éŒ„å™¨ï¼Œä»¥ä¾¿åœ¨å·¥å…·åŸ·è¡Œæ™‚æä¾›æœ‰ç”¨çš„è¼¸å‡º
# é€™å°æ–¼åœ¨èƒŒæ™¯åŸ·è¡Œæ™‚é€²è¡ŒåµéŒ¯è‡³é—œé‡è¦
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler() # ç›´æ¥è¼¸å‡ºåˆ° stderr
    ]
)
log = logging.getLogger('transcriber_tool')

class Transcriber:
    """
    ä¸€å€‹ç¨ç«‹çš„è½‰éŒ„å·¥å…·é¡åˆ¥ã€‚
    å®ƒåœ¨åˆå§‹åŒ–æ™‚è¼‰å…¥æŒ‡å®šçš„ faster-whisper æ¨¡å‹ï¼Œä¸¦æä¾›ä¸€å€‹æ–¹æ³•ä¾†åŸ·è¡Œè½‰éŒ„ã€‚
    é€™å€‹ç‰ˆæœ¬è¢«ç°¡åŒ–äº†ï¼Œç§»é™¤äº†å–®ä¾‹æ¨¡å¼å’Œå¤šæ¨¡å‹å¿«å–ï¼Œå› ç‚ºå®ƒè¢«è¨­è¨ˆç‚ºåœ¨
    ä¸€å€‹éš”é›¢çš„ã€ä¸€æ¬¡æ€§çš„ã€Œé çƒ˜çƒ¤ã€ç’°å¢ƒä¸­é‹è¡Œã€‚
    """
    def __init__(self, model_size: str):
        """
        åœ¨å¯¦ä¾‹åŒ–æ™‚ç›´æ¥è¼‰å…¥æ¨¡å‹ã€‚
        """
        self.model_size = model_size
        self.model = self._load_model()

    def _load_model(self):
        """
        æ ¹æ“šæŒ‡å®šçš„æ¨¡å‹å¤§å°è¼‰å…¥ faster-whisper æ¨¡å‹ã€‚
        """
        log.info(f"ğŸ§  é–‹å§‹è¼‰å…¥ '{self.model_size}' æ¨¡å‹...")
        start_time = time.time()
        try:
            from faster_whisper import WhisperModel
            # åœ¨å·¥å…·åŒ–åŸ·è¡Œä¸­ï¼Œæˆ‘å€‘å¯ä»¥å‡è¨­ç’°å¢ƒæ˜¯å›ºå®šçš„ï¼Œ
            # ä¾‹å¦‚ï¼Œç¸½æ˜¯ä½¿ç”¨ CPUã€‚æœªä¾†å¯ä»¥é€éåƒæ•¸å‚³éä¾†å¢åŠ å½ˆæ€§ã€‚
            model = WhisperModel(self.model_size, device="cpu", compute_type="int8")
            duration = time.time() - start_time
            log.info(f"âœ… æˆåŠŸè¼‰å…¥ '{self.model_size}' æ¨¡å‹ï¼è€—æ™‚: {duration:.2f} ç§’ã€‚")
            return model
        except ImportError as e:
            log.critical(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼šç¼ºå°‘ 'faster_whisper' æ¨¡çµ„ã€‚è«‹ç¢ºèªç’°å¢ƒå·²æ­£ç¢ºå®‰è£ã€‚")
            raise e
        except Exception as e:
            log.critical(f"âŒ è¼‰å…¥ '{self.model_size}' æ¨¡å‹æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            raise e

    def transcribe(self, audio_path: str, language: str) -> str:
        """
        åŸ·è¡ŒéŸ³è¨Šè½‰éŒ„çš„æ ¸å¿ƒæ–¹æ³•ã€‚
        """
        log.info(f"ğŸ¤ é–‹å§‹è™•ç†è½‰éŒ„ä»»å‹™: {audio_path}")
        if not self.model:
            log.error("âŒ æ¨¡å‹æœªè¢«è¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œè½‰éŒ„ã€‚")
            raise RuntimeError("æ¨¡å‹æœªè¢«è¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œè½‰éŒ„ã€‚")

        try:
            start_time = time.time()
            log.info("æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œé–‹å§‹è½‰éŒ„...")

            segments, info = self.model.transcribe(audio_path, beam_size=5, language=language, word_timestamps=True)

            detected_lang_msg = f"'{info.language}' (æ©Ÿç‡: {info.language_probability:.2f})"
            if language:
                log.info(f"ğŸŒ ä½¿ç”¨è€…æŒ‡å®šèªè¨€: '{language}'ï¼Œæ¨¡å‹åµæ¸¬åˆ° {detected_lang_msg}")
            else:
                log.info(f"ğŸŒ æœªæŒ‡å®šèªè¨€ï¼Œæ¨¡å‹è‡ªå‹•åµæ¸¬åˆ° {detected_lang_msg}")

            # --- ä¸²æµå¼è¼¸å‡º ---
            # æˆ‘å€‘ä¸å†ä¸€æ¬¡æ€§å›å‚³æ•´å€‹æ–‡æœ¬ï¼Œè€Œæ˜¯é€å¥å°å‡º
            cc = OpenCC('s2twp') if info.language.lower().startswith('zh') else None
            if cc:
                log.info("ğŸ”„ åµæ¸¬åˆ°ä¸­æ–‡ï¼Œå°‡å°æ¯å¥é€²è¡Œç¹é«”åŒ–è™•ç†ã€‚")

            total_transcript = []
            for segment in segments:
                segment_text = segment.text.strip()
                if cc:
                    segment_text = cc.convert(segment_text)

                # å»ºç«‹ä¸€å€‹ JSON ç‰©ä»¶ä¾†æ¨™æº–åŒ–è¼¸å‡º
                output_data = {
                    "type": "segment",
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment_text
                }
                # ä½¿ç”¨ flush=True ç¢ºä¿å³æ™‚è¼¸å‡º
                print(json.dumps(output_data, ensure_ascii=False), flush=True)
                total_transcript.append(segment_text)

            processing_time = time.time() - start_time
            log.info(f"ğŸ“ è½‰éŒ„å®Œæˆã€‚è€—æ™‚: {processing_time:.2f} ç§’ã€‚")

            # åœ¨æœ€å¾Œï¼Œè¼¸å‡ºä¸€å€‹åŒ…å«æœ€çµ‚çµ±è¨ˆè³‡è¨Šçš„ JSON ç‰©ä»¶
            final_info = {
                "type": "final",
                "audio_duration": info.duration,
                "processing_time": processing_time
            }
            print(json.dumps(final_info), flush=True)

            # ç‚ºäº†ç›¸å®¹åŸæœ‰çš„æª”æ¡ˆå¯«å…¥é‚è¼¯ï¼Œæˆ‘å€‘å›å‚³å®Œæ•´çš„æ–‡æœ¬
            return "".join(total_transcript)

        except Exception as e:
            log.error(f"âŒ è½‰éŒ„éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            raise e

import json
import sys
from faster_whisper.utils import get_assets_path

def check_model(model_size: str):
    """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰"""
    try:
        # é€™æ˜¯ faster-whisper å…§éƒ¨ç”¨ä¾†æ‰¾æ¨¡å‹è·¯å¾‘çš„æ–¹æ³•
        model_path = get_assets_path(f"ctranslate2-4-avx2/whisper-{model_size}-ct2")
        if (Path(model_path) / "config.json").is_file():
            print("exists")
            log.info(f"âœ… æ¨¡å‹ '{model_size}' å·²å­˜åœ¨æ–¼: {model_path}")
        else:
            print("not_exists")
            log.info(f"â“ æ¨¡å‹ '{model_size}' ä¸å­˜åœ¨ã€‚")
    except Exception as e:
        print("not_exists")
        log.error(f"æª¢æŸ¥æ¨¡å‹ '{model_size}' æ™‚å‡ºéŒ¯: {e}")

def download_model(model_size: str):
    """ä¸‹è¼‰æ¨¡å‹ä¸¦å›å ±é€²åº¦"""
    log.info(f"ğŸ“¥ é–‹å§‹ä¸‹è¼‰æ¨¡å‹: {model_size}")
    # åˆ©ç”¨ _load_model çš„å‰¯ä½œç”¨ä¾†ä¸‹è¼‰
    try:
        Transcriber(model_size=model_size)
        print(json.dumps({"progress": 100, "log": "æ¨¡å‹ä¸‹è¼‰å®Œæˆ"}), flush=True)
    except Exception as e:
        print(json.dumps({"progress": 100, "log": f"ä¸‹è¼‰å¤±æ•—: {e}"}), flush=True)
        log.critical(f"ä¸‹è¼‰æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        exit(1)


def main():
    """
    ä¸»å‡½æ•¸ï¼Œæ ¹æ“š command åƒæ•¸åŸ·è¡Œä¸åŒæ“ä½œã€‚
    """
    parser = argparse.ArgumentParser(description="ä¸€å€‹å¤šåŠŸèƒ½è½‰éŒ„èˆ‡æ¨¡å‹ç®¡ç†å·¥å…·ã€‚")
    parser.add_argument("--command", type=str, default="transcribe", choices=["transcribe", "check", "download"], help="è¦åŸ·è¡Œçš„æ“ä½œã€‚")
    # è½‰éŒ„åƒæ•¸
    parser.add_argument("--audio_file", type=str, help="[transcribe] éœ€è¦è½‰éŒ„çš„éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ã€‚")
    parser.add_argument("--output_file", type=str, help="[transcribe] å„²å­˜è½‰éŒ„çµæœçš„æª”æ¡ˆè·¯å¾‘ã€‚")
    parser.add_argument("--language", type=str, default=None, help="[transcribe] éŸ³è¨Šçš„èªè¨€ã€‚")
    # é€šç”¨åƒæ•¸
    parser.add_argument("--model_size", type=str, default="tiny", help="è¦ä½¿ç”¨/æª¢æŸ¥/ä¸‹è¼‰çš„æ¨¡å‹å¤§å°ã€‚")

    args = parser.parse_args()

    if args.command == "check":
        check_model(args.model_size)
        return

    if args.command == "download":
        download_model(args.model_size)
        return

    # --- é è¨­ç‚ºè½‰éŒ„ ---
    if not args.audio_file or not args.output_file:
        parser.error("--audio_file å’Œ --output_file æ˜¯ 'transcribe' å‘½ä»¤çš„å¿…è¦åƒæ•¸ã€‚")

    log.info(f"ğŸš€ å·¥å…·å•Ÿå‹• (è½‰éŒ„æ¨¡å¼)ï¼Œåƒæ•¸: {args}")
    try:
        transcriber = Transcriber(model_size=args.model_size)
        result_text = transcriber.transcribe(args.audio_file, args.language)
        output_path = Path(args.output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(result_text, encoding='utf-8')
        log.info(f"âœ… æˆåŠŸå°‡çµæœå¯«å…¥åˆ°: {args.output_file}")

    except Exception as e:
        log.critical(f"âŒ åœ¨åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤: {e}", exc_info=True)
        # å¯ä»¥åœ¨æ­¤è™•å»ºç«‹ä¸€å€‹éŒ¯èª¤æ¨™è¨˜æª”æ¡ˆï¼Œä»¥ä¾¿å¤–éƒ¨åŸ·è¡Œå™¨çŸ¥é“ç™¼ç”Ÿäº†å•é¡Œ
        error_file = Path(args.output_file).parent / f"{Path(args.output_file).stem}.error"
        error_file.write_text(str(e), encoding='utf-8')
        exit(1) # ä»¥éé›¶ç‹€æ…‹ç¢¼é€€å‡ºï¼Œè¡¨ç¤ºå¤±æ•—

if __name__ == "__main__":
    main()
