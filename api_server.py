# api_server.py
import uuid
import shutil
import logging
import json
import subprocess
import sys
import threading
import asyncio
import os
import time
from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException, WebSocket, WebSocketDisconnect, Query
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pathlib import Path
from typing import Optional, Dict, List

# åŒ¯å…¥æ–°çš„è³‡æ–™åº«å®¢æˆ¶ç«¯
# from db import database # REMOVED: No longer used directly
from db.client import get_client

# --- JULES æ–¼ 2025-08-09 çš„ä¿®æ”¹ï¼šè¨­å®šæ‡‰ç”¨ç¨‹å¼å…¨åŸŸæ™‚å€ ---
# ç‚ºäº†ç¢ºä¿æ‰€æœ‰æ—¥èªŒå’Œè³‡æ–™åº«æ™‚é–“æˆ³éƒ½ä½¿ç”¨ä¸€è‡´çš„æ™‚å€ï¼Œæˆ‘å€‘åœ¨æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•çš„
# æœ€æ—©æœŸéšæ®µå°±å°‡æ™‚å€ç’°å¢ƒè®Šæ•¸è¨­å®šç‚º 'Asia/Taipei'ã€‚
os.environ['TZ'] = 'Asia/Taipei'
if sys.platform != 'win32':
    time.tzset()
# --- æ™‚å€è¨­å®šçµæŸ ---

# --- æ¨¡å¼è¨­å®š ---
# é€éå‘½ä»¤åˆ—æ——æ¨™æ±ºå®šæ˜¯å¦å•Ÿç”¨æ¨¡æ“¬æ¨¡å¼
import argparse
cli_parser = argparse.ArgumentParser()
cli_parser.add_argument(
    "--mock",
    action="store_true",
    help="å•Ÿç”¨æ¨¡æ“¬æ¨¡å¼ï¼Œå°‡ä½¿ç”¨ mock_transcriber.pyã€‚"
)
cli_args, _ = cli_parser.parse_known_args()
IS_MOCK_MODE = cli_args.mock

# --- è·¯å¾‘è¨­å®š ---
# ä»¥æ­¤æª”æ¡ˆç‚ºåŸºæº–ï¼Œå®šç¾©å°ˆæ¡ˆæ ¹ç›®éŒ„
ROOT_DIR = Path(__file__).resolve().parent

# --- æ—¥èªŒè¨­å®š ---
# ä¸»æ—¥èªŒå™¨
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()] # è¼¸å‡ºåˆ°æ§åˆ¶å°
)
log = logging.getLogger('api_server')

def setup_database_logging():
    """è¨­å®šè³‡æ–™åº«æ—¥èªŒè™•ç†å™¨ã€‚"""
    try:
        from db.log_handler import DatabaseLogHandler
        root_logger = logging.getLogger()
        # æª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰åŒé¡å‹çš„ handlerï¼Œé¿å…é‡è¤‡åŠ å…¥
        if not any(isinstance(h, DatabaseLogHandler) for h in root_logger.handlers):
            root_logger.addHandler(DatabaseLogHandler(source='api_server'))
            log.info("è³‡æ–™åº«æ—¥èªŒè™•ç†å™¨è¨­å®šå®Œæˆ (source: api_server)ã€‚")
    except Exception as e:
        log.error(f"æ•´åˆè³‡æ–™åº«æ—¥èªŒæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)

# å»ºç«‹ä¸€å€‹å°ˆé–€ç”¨ä¾†è¨˜éŒ„å‰ç«¯æ“ä½œçš„æ—¥èªŒå™¨
run_log_file = ROOT_DIR / "run_log.txt"
action_log = logging.getLogger('frontend_action')
action_log.setLevel(logging.INFO)

# ç‚ºäº†ç¢ºä¿æ¯æ¬¡åŸ·è¡Œéƒ½æ˜¯ä¹¾æ·¨çš„ï¼Œå…ˆæ¸…ç©ºæ—¥èªŒæª”æ¡ˆ
if run_log_file.exists():
    run_log_file.unlink()

# ç‚º action_log æ–°å¢ä¸€å€‹ FileHandler
file_handler = logging.FileHandler(run_log_file, encoding='utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))
action_log.addHandler(file_handler)
action_log.propagate = False # é˜²æ­¢æ—¥èªŒå‚³æ’­åˆ° root loggerï¼Œé¿å…åœ¨æ§åˆ¶å°é‡è¤‡è¼¸å‡º

# --- WebSocket é€£ç·šç®¡ç†å™¨ ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        log.info(f"æ–°ç”¨æˆ¶ç«¯é€£ç·šã€‚ç›®å‰å…± {len(self.active_connections)} å€‹é€£ç·šã€‚")

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
        log.info(f"ä¸€å€‹ç”¨æˆ¶ç«¯é›¢ç·šã€‚ç›®å‰å…± {len(self.active_connections)} å€‹é€£ç·šã€‚")

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

    async def broadcast_json(self, data: dict):
        for connection in self.active_connections:
            await connection.send_json(data)

manager = ConnectionManager()


# --- DB å®¢æˆ¶ç«¯ ---
# åœ¨æ¨¡çµ„åŠ è¼‰æ™‚ç²å–å®¢æˆ¶ç«¯å–®ä¾‹
# å®¢æˆ¶ç«¯å…§éƒ¨æœ‰é‡è©¦æ©Ÿåˆ¶ï¼Œæœƒç­‰å¾… DB ç®¡ç†è€…æœå‹™å°±ç·’
db_client = get_client()

# --- FastAPI æ‡‰ç”¨å¯¦ä¾‹ ---
app = FastAPI(title="é³³å‡°éŸ³è¨Šè½‰éŒ„å„€ API (v3 - é‡æ§‹)", version="3.0")

# --- è·¯å¾‘è¨­å®š ---
# ä»¥æ­¤æª”æ¡ˆç‚ºåŸºæº–ï¼Œå®šç¾©å°ˆæ¡ˆæ ¹ç›®éŒ„
ROOT_DIR = Path(__file__).resolve().parent
# æ–°çš„ä¸Šå‚³æª”æ¡ˆå„²å­˜ç›®éŒ„
UPLOADS_DIR = ROOT_DIR / "uploads"
# éœæ…‹æª”æ¡ˆç›®éŒ„
STATIC_DIR = ROOT_DIR / "static"

# ç¢ºä¿ç›®éŒ„å­˜åœ¨
UPLOADS_DIR.mkdir(exist_ok=True)
if not STATIC_DIR.exists():
    log.warning(f"éœæ…‹æª”æ¡ˆç›®éŒ„ {STATIC_DIR} ä¸å­˜åœ¨ï¼Œå‰ç«¯é é¢å¯èƒ½ç„¡æ³•è¼‰å…¥ã€‚")
else:
    app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")


# --- API ç«¯é» ---

@app.get("/", response_class=HTMLResponse)
async def serve_frontend(request: Request):
    """æ ¹ç«¯é»ï¼Œæä¾›å‰ç«¯æ“ä½œä»‹é¢ã€‚"""
    html_file_path = STATIC_DIR / "mp3.html"
    if not html_file_path.is_file():
        log.error(f"æ‰¾ä¸åˆ°å‰ç«¯æª”æ¡ˆ: {html_file_path}")
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°å‰ç«¯ä»‹é¢æª”æ¡ˆ (mp3.html)")
    return HTMLResponse(content=html_file_path.read_text(encoding="utf-8"), status_code=200)


def check_model_exists(model_size: str) -> bool:
    """
    æª¢æŸ¥æŒ‡å®šçš„ Whisper æ¨¡å‹æ˜¯å¦å·²ç¶“è¢«ä¸‹è¼‰åˆ°æœ¬åœ°å¿«å–ã€‚
    """
    tool_script = "tools/mock_transcriber.py" if IS_MOCK_MODE else "tools/transcriber.py"
    log.info(f"ä½¿ç”¨ '{tool_script}' æª¢æŸ¥æ¨¡å‹ '{model_size}' æ˜¯å¦å­˜åœ¨...")

    # æˆ‘å€‘é€éå‘¼å«ä¸€å€‹è¼•é‡ç´šçš„å·¥å…·è…³æœ¬ä¾†æª¢æŸ¥ã€‚
    check_command = [sys.executable, tool_script, "--command=check", f"--model_size={model_size}"]
    try:
        # åœ¨æ¨¡æ“¬æ¨¡å¼ä¸‹ï¼Œmock_transcriber.py æœƒæ°¸é å›å‚³ "exists"
        result = subprocess.run(check_command, capture_output=True, text=True, check=True)
        output = result.stdout.strip().lower()
        log.info(f"æ¨¡å‹ '{model_size}' æª¢æŸ¥çµæœ: {output}")
        # å¿…é ˆå®Œå…¨åŒ¹é… "exists"ï¼Œé¿å… "not_exists" è¢«éŒ¯èª¤åˆ¤æ–·ç‚º True
        return output == "exists"
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        log.error(f"æª¢æŸ¥æ¨¡å‹ '{model_size}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

@app.post("/api/transcribe", status_code=202)
async def create_transcription_task(
    file: UploadFile = File(...),
    model_size: str = Form("tiny"),
    language: Optional[str] = Form(None),
    beam_size: int = Form(5)
):
    """
    æ¥æ”¶éŸ³è¨Šæª”æ¡ˆï¼Œæ ¹æ“šæ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œæ±ºå®šæ˜¯ç›´æ¥å»ºç«‹è½‰éŒ„ä»»å‹™ï¼Œ
    é‚„æ˜¯å…ˆå»ºç«‹ä¸€å€‹ä¸‹è¼‰ä»»å‹™å’Œä¸€å€‹ä¾è³´æ–¼å®ƒçš„è½‰éŒ„ä»»å‹™ã€‚
    """
    # 1. æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    model_is_present = check_model_exists(model_size)

    # 2. ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
    transcribe_task_id = str(uuid.uuid4())
    file_extension = Path(file.filename).suffix or ".wav"
    saved_file_path = UPLOADS_DIR / f"{transcribe_task_id}{file_extension}"
    try:
        with open(saved_file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        log.info(f"æª”æ¡ˆå·²å„²å­˜è‡³: {saved_file_path}")
    except Exception as e:
        log.error(f"âŒ å„²å­˜æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç„¡æ³•å„²å­˜ä¸Šå‚³çš„æª”æ¡ˆ: {e}")
    finally:
        await file.close()

    # 3. æ ¹æ“šæ¨¡å‹æ˜¯å¦å­˜åœ¨ä¾†å»ºç«‹ä»»å‹™
    transcription_payload = {
        "input_file": str(saved_file_path),
        "output_dir": "transcripts",
        "model_size": model_size,
        "language": language,
        "beam_size": beam_size
    }

    if model_is_present:
        # æ¨¡å‹å·²å­˜åœ¨ï¼Œç›´æ¥å»ºç«‹è½‰éŒ„ä»»å‹™
        log.info(f"âœ… æ¨¡å‹ '{model_size}' å·²å­˜åœ¨ï¼Œç›´æ¥å»ºç«‹è½‰éŒ„ä»»å‹™: {transcribe_task_id}")
        db_client.add_task(transcribe_task_id, json.dumps(transcription_payload), task_type='transcribe')
        # JULES: ä¿®æ­£ API å›æ‡‰ï¼Œä½¿å…¶èˆ‡å‰ç«¯çš„é€šç”¨è™•ç†é‚è¼¯ä¸€è‡´ï¼Œè£œä¸Š type æ¬„ä½
        return {"task_id": transcribe_task_id, "type": "transcribe"}
    else:
        # æ¨¡å‹ä¸å­˜åœ¨ï¼Œå»ºç«‹ä¸‹è¼‰ä»»å‹™å’Œä¾è³´çš„è½‰éŒ„ä»»å‹™
        download_task_id = str(uuid.uuid4())
        log.warning(f"âš ï¸ æ¨¡å‹ '{model_size}' ä¸å­˜åœ¨ã€‚å»ºç«‹ä¸‹è¼‰ä»»å‹™ '{download_task_id}' å’Œä¾è³´çš„è½‰éŒ„ä»»å‹™ '{transcribe_task_id}'")

        download_payload = {"model_size": model_size}
        db_client.add_task(download_task_id, json.dumps(download_payload), task_type='download')

        db_client.add_task(transcribe_task_id, json.dumps(transcription_payload), task_type='transcribe', depends_on=download_task_id)

        # æˆ‘å€‘å›å‚³è½‰éŒ„ä»»å‹™çš„ IDï¼Œè®“å‰ç«¯å¯ä»¥è¿½è¹¤æœ€çµ‚çµæœ
        return JSONResponse(content={"tasks": [
            {"task_id": download_task_id, "type": "download"},
            {"task_id": transcribe_task_id, "type": "transcribe"}
        ]})


@app.get("/api/status/{task_id}")
async def get_task_status_endpoint(task_id: str):
    """
    æ ¹æ“šä»»å‹™ IDï¼Œå¾è³‡æ–™åº«æŸ¥è©¢ä»»å‹™ç‹€æ…‹ã€‚
    """
    log.debug(f"ğŸ” æ­£åœ¨æŸ¥è©¢ä»»å‹™ç‹€æ…‹: {task_id}")
    status_info = db_client.get_task_status(task_id)

    if not status_info:
        log.warning(f"â“ æ‰¾ä¸åˆ°ä»»å‹™ ID: {task_id}")
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æŒ‡å®šçš„ä»»å‹™ ID")

    # DBClient å›å‚³çš„å·²ç¶“æ˜¯ dictï¼Œç„¡éœ€è½‰æ›
    response_data = status_info

    # å˜—è©¦è§£æ JSON çµæœ
    if response_data.get("result"):
        try:
            response_data["result"] = json.loads(response_data["result"])
        except json.JSONDecodeError:
            # å¦‚æœä¸æ˜¯åˆæ³•çš„ JSONï¼Œå°±ä»¥åŸå§‹å­—ä¸²å½¢å¼å›å‚³
            log.warning(f"ä»»å‹™ {task_id} çš„çµæœä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚")
            pass

    log.info(f"âœ… å›å‚³ä»»å‹™ {task_id} çš„ç‹€æ…‹: {response_data['status']}")
    return JSONResponse(content=response_data)


@app.post("/api/log/action", status_code=200)
async def log_frontend_action(payload: Dict):
    """
    æ¥æ”¶å‰ç«¯ç™¼é€çš„æ“ä½œæ—¥èªŒï¼Œä¸¦ä½¿ç”¨å°ˆé–€çš„æ—¥èªŒå™¨è¨˜éŒ„åˆ°æª”æ¡ˆã€‚
    """
    action = payload.get("action", "unknown_action")
    # ç‚ºäº†è®“æ—¥èªŒæª”æ¡ˆæ›´å…·å¯è®€æ€§ï¼Œæˆ‘å€‘åªè¨˜éŒ„ action æœ¬èº«
    action_log.info(f"[FRONTEND ACTION] {action}")
    log.info(f"ğŸ“ è¨˜éŒ„å‰ç«¯æ“ä½œ: {action}") # åœ¨æ§åˆ¶å°ä¹Ÿé¡¯ç¤ºæ—¥èªŒ
    return {"status": "logged"}


import psutil

@app.get("/api/application_status")
async def get_application_status():
    """
    ç²å–æ ¸å¿ƒæ‡‰ç”¨çš„ç‹€æ…‹ï¼Œä¾‹å¦‚æ¨¡å‹æ˜¯å¦å·²è¼‰å…¥ã€‚
    """
    # TODO: é€™éƒ¨åˆ†å°‡åœ¨å¾ŒçºŒèˆ‡ worker ç‹€æ…‹åŒæ­¥
    return {
        "model_loaded": False,
        "active_model": None,
        "message": "ç­‰å¾…ä½¿ç”¨è€…æ“ä½œ"
    }

@app.get("/api/system_stats")
async def get_system_stats():
    """
    ç²å–ä¸¦å›å‚³ç•¶å‰çš„ç³»çµ±è³‡æºä½¿ç”¨ç‹€æ…‹ï¼ˆCPU, RAM, GPUï¼‰ã€‚
    """
    # CPU
    cpu_usage = psutil.cpu_percent(interval=0.1)

    # RAM
    ram = psutil.virtual_memory()
    ram_usage = ram.percent

    # GPU (é€é nvidia-smi)
    gpu_usage = None
    gpu_detected = False
    try:
        # åŸ·è¡Œ nvidia-smi å‘½ä»¤
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'],
            capture_output=True, text=True, check=True
        )
        # è§£æè¼¸å‡º
        gpu_usage = float(result.stdout.strip())
        gpu_detected = True
    except (FileNotFoundError, subprocess.CalledProcessError) as e:
        # nvidia-smi ä¸å­˜åœ¨æˆ–åŸ·è¡Œå¤±æ•—
        log.debug(f"ç„¡æ³•ç²å– GPU è³‡è¨Š: {e}")
        gpu_usage = None
        gpu_detected = False

    return {
        "cpu_usage": cpu_usage,
        "ram_usage": ram_usage,
        "gpu_usage": gpu_usage,
        "gpu_detected": gpu_detected,
    }


@app.get("/api/tasks")
async def get_all_tasks_endpoint():
    """
    ç²å–æ‰€æœ‰ä»»å‹™çš„åˆ—è¡¨ï¼Œç”¨æ–¼å‰ç«¯å±•ç¤ºã€‚
    """
    tasks = db_client.get_all_tasks()
    # å˜—è©¦è§£æ payload å’Œ result ä¸­çš„ JSON å­—ä¸²
    for task in tasks:
        try:
            if task.get("payload"):
                task["payload"] = json.loads(task["payload"])
        except (json.JSONDecodeError, TypeError):
            log.warning(f"ä»»å‹™ {task.get('task_id')} çš„ payload ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚")
            pass # ä¿æŒåŸæ¨£
        try:
            if task.get("result"):
                task["result"] = json.loads(task["result"])
        except (json.JSONDecodeError, TypeError):
            log.warning(f"ä»»å‹™ {task.get('task_id')} çš„ result ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚")
            pass # ä¿æŒåŸæ¨£
    return JSONResponse(content=tasks)


@app.get("/api/logs")
async def get_system_logs_endpoint(
    levels: List[str] = Query(None, alias="level"),
    sources: List[str] = Query(None, alias="source")
):
    """
    ç²å–ç³»çµ±æ—¥èªŒï¼Œå¯æŒ‰ç­‰ç´šå’Œä¾†æºé€²è¡Œç¯©é¸ã€‚
    """
    log.info(f"API: æ­£åœ¨æŸ¥è©¢ç³»çµ±æ—¥èªŒ (Levels: {levels}, Sources: {sources})")
    try:
        logs = db_client.get_system_logs(levels=levels, sources=sources)
        return JSONResponse(content=logs)
    except Exception as e:
        log.error(f"âŒ æŸ¥è©¢ç³»çµ±æ—¥èªŒæ™‚ API å‡ºéŒ¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="æŸ¥è©¢ç³»çµ±æ—¥èªŒæ™‚ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤")


@app.get("/api/download/{task_id}")
async def download_transcript(task_id: str):
    """
    æ ¹æ“šä»»å‹™ ID ä¸‹è¼‰è½‰éŒ„çµæœæª”æ¡ˆã€‚
    """
    task = db_client.get_task_status(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æŒ‡å®šçš„ä»»å‹™ IDã€‚")

    if task['status'] != 'completed':
        raise HTTPException(status_code=400, detail="ä»»å‹™å°šæœªå®Œæˆï¼Œç„¡æ³•ä¸‹è¼‰ã€‚")

    try:
        # å¾ result æ¬„ä½è§£æå‡ºæª”å
        result_data = json.loads(task['result'])
        # ä¾åºæª¢æŸ¥å¯èƒ½çš„è·¯å¾‘éµåï¼Œä»¥æ”¯æ´æ‰€æœ‰ä»»å‹™é¡å‹
        output_filename = (
            result_data.get("transcript_path") or
            result_data.get("output_path") or
            result_data.get("html_report_path") or
            result_data.get("pdf_report_path")
        )

        if not output_filename:
            raise HTTPException(status_code=500, detail="ä»»å‹™çµæœä¸­æœªåŒ…å«æœ‰æ•ˆçš„æª”æ¡ˆè·¯å¾‘ã€‚")

        file_path = Path(output_filename)
        if not file_path.is_file():
            log.error(f"âŒ è½‰éŒ„æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
            raise HTTPException(status_code=404, detail="è½‰éŒ„æª”æ¡ˆéºå¤±æˆ–ç„¡æ³•è®€å–ã€‚")

        # æä¾›æª”æ¡ˆä¸‹è¼‰
        from fastapi.responses import FileResponse
        ext = file_path.suffix.lower()
        if ext == '.pdf':
            media_type = 'application/pdf'
        elif ext == '.html':
            media_type = 'text/html'
        else:
            media_type = 'text/plain'
        return FileResponse(path=file_path, filename=file_path.name, media_type=media_type)

    except (json.JSONDecodeError, KeyError) as e:
        log.error(f"âŒ è§£æä»»å‹™ {task_id} çš„çµæœæ™‚å‡ºéŒ¯: {e}")
        raise HTTPException(status_code=500, detail="ç„¡æ³•è§£æä»»å‹™çµæœã€‚")


# --- YouTube åŠŸèƒ½ç›¸é—œ API ---

@app.get("/api/youtube/status")
async def get_youtube_status():
    """æª¢æŸ¥ YouTube åŠŸèƒ½æ˜¯å¦å·²å•Ÿç”¨ (é€éæª¢æŸ¥ GOOGLE_API_KEY)ã€‚"""
    # åœ¨æ¨¡æ“¬æ¨¡å¼ä¸‹ï¼Œæ°¸é å›å‚³å•Ÿç”¨
    if IS_MOCK_MODE:
        return {"enabled": True}
    api_key = os.environ.get("GOOGLE_API_KEY")
    return {"enabled": bool(api_key)}

@app.get("/api/youtube/models")
async def get_youtube_models():
    """ç²å–å¯ç”¨çš„ Gemini æ¨¡å‹åˆ—è¡¨ã€‚"""
    # åœ¨æ¨¡æ“¬æ¨¡å¼ä¸‹ï¼Œå›å‚³ä¸€å€‹å›ºå®šçš„å‡åˆ—è¡¨
    if IS_MOCK_MODE:
        return {
            "models": [
                {"id": "gemini-pro-mock", "name": "Gemini Pro (æ¨¡æ“¬)"},
                {"id": "gemini-1.5-flash-mock", "name": "Gemini 1.5 Flash (æ¨¡æ“¬)"}
            ]
        }

    # çœŸå¯¦æ¨¡å¼ä¸‹ï¼Œå¯ä»¥å¾ gemini_processor.py ç²å–
    try:
        tool_script = "tools/gemini_processor.py"
        cmd = [sys.executable, tool_script, "--command=list_models"]
        result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8')
        models = json.loads(result.stdout)
        return {"models": models}
    except Exception as e:
        log.error(f"ç²å– Gemini æ¨¡å‹åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ç„¡æ³•ç²å– Gemini æ¨¡å‹åˆ—è¡¨ã€‚")

@app.post("/api/youtube/process", status_code=202)
async def process_youtube_urls(request: Request):
    """æ¥æ”¶ä¸€æˆ–å¤šå€‹ YouTube URLï¼Œç‚ºæ¯ä¸€å€‹ URL å»ºç«‹è™•ç†ä»»å‹™ã€‚"""
    payload = await request.json()
    urls = payload.get("urls", [])
    model = payload.get("model")

    if not urls or not model:
        raise HTTPException(status_code=400, detail="è«‹æ±‚ä¸­å¿…é ˆåŒ…å« 'urls' å’Œ 'model'ã€‚")

    tasks = []
    for url in urls:
        if not url.strip():
            continue

        download_task_id = str(uuid.uuid4())
        process_task_id = str(uuid.uuid4())

        download_payload = { "url": url, "output_dir": str(UPLOADS_DIR) }
        process_payload = { "model": model, "output_dir": "transcripts" }

        db_client.add_task(download_task_id, json.dumps(download_payload), task_type='youtube_download')
        db_client.add_task(process_task_id, json.dumps(process_payload), task_type='gemini_process', depends_on=download_task_id)

        tasks.append({
            "url": url,
            "type": "youtube", # æ–°å¢é¡å‹ä»¥åˆ©å‰ç«¯è¾¨è­˜
            "download_task_id": download_task_id,
            "process_task_id": process_task_id
        })

    return JSONResponse(content={"message": f"å·²ç‚º {len(tasks)} å€‹ URL å»ºç«‹è™•ç†ä»»å‹™ã€‚", "tasks": tasks})


def trigger_model_download(model_size: str, loop: asyncio.AbstractEventLoop):
    """
    åœ¨ä¸€å€‹å–®ç¨çš„åŸ·è¡Œç·’ä¸­åŸ·è¡Œæ¨¡å‹ä¸‹è¼‰ï¼Œä¸¦é€é WebSocket å›å ±çµæœã€‚
    é€™å€‹ç‰ˆæœ¬æœƒé€è¡Œè®€å– stdout ä¾†ç²å–å³æ™‚çš„ JSON é€²åº¦æ›´æ–°ã€‚
    """
    def _download_in_thread():
        log.info(f"ğŸ§µ [åŸ·è¡Œç·’] é–‹å§‹ä¸‹è¼‰æ¨¡å‹: {model_size}")
        try:
            tool_script = "tools/mock_transcriber.py" if IS_MOCK_MODE else "tools/transcriber.py"
            cmd = [sys.executable, tool_script, "--command=download", f"--model_size={model_size}"]

            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                bufsize=1 # Line-buffered
            )

            # é€è¡Œè®€å– stdout ä»¥ç²å–é€²åº¦æ›´æ–°
            if process.stdout:
                for line in iter(process.stdout.readline, ''):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        data = json.loads(line)
                        # å»ºç«‹ WebSocket è¨Šæ¯
                        message = {
                            "type": "DOWNLOAD_STATUS",
                            "payload": {
                                "model": model_size,
                                "status": "downloading",
                                **data  # é€™æœƒåŒ…å« 'type', 'percent', 'description' ç­‰
                            }
                        }
                        asyncio.run_coroutine_threadsafe(manager.broadcast_json(message), loop)
                    except json.JSONDecodeError:
                        log.warning(f"[åŸ·è¡Œç·’] ç„¡æ³•è§£æä¾†è‡ª transcriber çš„ä¸‹è¼‰é€²åº¦ JSON: {line}")

            process.wait() # ç­‰å¾…ç¨‹åºçµæŸ

            # æ ¹æ“šç¨‹åºçš„è¿”å›ç¢¼æ±ºå®šæœ€çµ‚ç‹€æ…‹
            if process.returncode == 0:
                log.info(f"âœ… [åŸ·è¡Œç·’] æ¨¡å‹ '{model_size}' ä¸‹è¼‰æˆåŠŸã€‚")
                message = {
                    "type": "DOWNLOAD_STATUS",
                    "payload": {"model": model_size, "status": "completed", "progress": 100}
                }
            else:
                stderr_output = process.stderr.read() if process.stderr else "N/A"
                log.error(f"âŒ [åŸ·è¡Œç·’] æ¨¡å‹ '{model_size}' ä¸‹è¼‰å¤±æ•—ã€‚ Stderr: {stderr_output}")
                message = {
                    "type": "DOWNLOAD_STATUS",
                    "payload": {"model": model_size, "status": "failed", "error": stderr_output}
                }

            asyncio.run_coroutine_threadsafe(manager.broadcast_json(message), loop)

        except Exception as e:
            log.error(f"âŒ [åŸ·è¡Œç·’] ä¸‹è¼‰åŸ·è¡Œç·’ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            message = {
                "type": "DOWNLOAD_STATUS",
                "payload": {"model": model_size, "status": "failed", "error": str(e)}
            }
            asyncio.run_coroutine_threadsafe(manager.broadcast_json(message), loop)

    # å»ºç«‹ä¸¦å•Ÿå‹•åŸ·è¡Œç·’
    thread = threading.Thread(target=_download_in_thread)
    thread.start()


def trigger_transcription(task_id: str, file_path: str, model_size: str, language: Optional[str], beam_size: int, loop: asyncio.AbstractEventLoop):
    """
    åœ¨ä¸€å€‹å–®ç¨çš„åŸ·è¡Œç·’ä¸­åŸ·è¡Œè½‰éŒ„ï¼Œä¸¦é€é WebSocket å³æ™‚ä¸²æµçµæœã€‚
    """
    def _transcribe_in_thread():
        log.info(f"ğŸ§µ [åŸ·è¡Œç·’] é–‹å§‹è™•ç†è½‰éŒ„ä»»å‹™: {task_id}ï¼Œæª”æ¡ˆ: {file_path}")

        # æº–å‚™ä¸€å€‹å‡çš„è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼Œå› ç‚º transcriber.py éœ€è¦å®ƒï¼Œä½†æˆ‘å€‘å¯¦éš›ä¸Šæ˜¯å¾ stdout è®€å–
        output_dir = ROOT_DIR / "transcripts"
        output_dir.mkdir(exist_ok=True)
        dummy_output_path = output_dir / f"{task_id}.txt"

        try:
            tool_script = "tools/mock_transcriber.py" if IS_MOCK_MODE else "tools/transcriber.py"
            cmd = [
                sys.executable,
                tool_script,
                "--command=transcribe",
                f"--audio_file={file_path}",
                f"--output_file={dummy_output_path}",
                f"--model_size={model_size}",
            ]
            if language:
                cmd.append(f"--language={language}")
            # æ–°å¢ beam_size åƒæ•¸
            cmd.append(f"--beam_size={beam_size}")

            log.info(f"åŸ·è¡Œè½‰éŒ„æŒ‡ä»¤: {' '.join(map(str, cmd))}")

            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8',
                bufsize=1 # Line-buffered
            )

            start_message = {
                "type": "TRANSCRIPTION_STATUS",
                "payload": {"task_id": task_id, "status": "starting", "filename": Path(file_path).name}
            }
            asyncio.run_coroutine_threadsafe(manager.broadcast_json(start_message), loop)

            if process.stdout:
                for line in iter(process.stdout.readline, ''):
                    line = line.strip()
                    if not line:
                        continue

                    try:
                        data = json.loads(line)
                        message = {
                            "type": "TRANSCRIPTION_UPDATE",
                            "payload": {"task_id": task_id, **data}
                        }
                        asyncio.run_coroutine_threadsafe(manager.broadcast_json(message), loop)
                    except json.JSONDecodeError:
                        log.warning(f"[åŸ·è¡Œç·’] ç„¡æ³•è§£æä¾†è‡ª transcriber çš„ JSON è¡Œ: {line}")

            process.wait()

            if process.returncode == 0:
                log.info(f"âœ… [åŸ·è¡Œç·’] è½‰éŒ„ä»»å‹™ '{task_id}' æˆåŠŸå®Œæˆã€‚")

                # è®€å–çµæœä¸¦æ›´æ–°è³‡æ–™åº«ç‹€æ…‹
                final_transcript = dummy_output_path.read_text(encoding='utf-8').strip()
                final_result_obj = {
                    "transcript": final_transcript,
                    "transcript_path": str(dummy_output_path)
                }
                db_client.update_task_status(task_id, 'completed', json.dumps(final_result_obj))
                log.info(f"âœ… [åŸ·è¡Œç·’] å·²å°‡ä»»å‹™ {task_id} çš„ç‹€æ…‹å’Œçµæœæ›´æ–°è‡³è³‡æ–™åº«ã€‚")

                final_message = {
                    "type": "TRANSCRIPTION_STATUS",
                    "payload": {"task_id": task_id, "status": "completed", "result": final_result_obj}
                }
            else:
                stderr_output = process.stderr.read() if process.stderr else "N/A"
                log.error(f"âŒ [åŸ·è¡Œç·’] è½‰éŒ„ä»»å‹™ '{task_id}' å¤±æ•—ã€‚è¿”å›ç¢¼: {process.returncode}ã€‚Stderr: {stderr_output}")
                final_message = {
                    "type": "TRANSCRIPTION_STATUS",
                    "payload": {"task_id": task_id, "status": "failed", "error": stderr_output}
                }

            asyncio.run_coroutine_threadsafe(manager.broadcast_json(final_message), loop)

        except Exception as e:
            log.error(f"âŒ [åŸ·è¡Œç·’] è½‰éŒ„åŸ·è¡Œç·’ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            error_message = {
                "type": "TRANSCRIPTION_STATUS",
                "payload": {"task_id": task_id, "status": "failed", "error": str(e)}
            }
            asyncio.run_coroutine_threadsafe(manager.broadcast_json(error_message), loop)

    thread = threading.Thread(target=_transcribe_in_thread)
    thread.start()


def trigger_youtube_processing(task_id: str, loop: asyncio.AbstractEventLoop):
    """åœ¨ä¸€å€‹å–®ç¨çš„åŸ·è¡Œç·’ä¸­åŸ·è¡Œ YouTube è™•ç†æµç¨‹ã€‚"""
    def _process_in_thread():
        log.info(f"ğŸ§µ [åŸ·è¡Œç·’] é–‹å§‹è™•ç† YouTube ä»»å‹™éˆï¼Œèµ·å§‹ä»»å‹™ ID: {task_id}")

        download_task_id = task_id

        try:
            # 1. ä¸‹è¼‰éŸ³è¨Š
            download_task_info = db_client.get_task_status(download_task_id)
            if not download_task_info:
                raise ValueError(f"æ‰¾ä¸åˆ°ä¸‹è¼‰ä»»å‹™ {download_task_id}")

            payload = json.loads(download_task_info['payload'])
            url = payload['url']

            asyncio.run_coroutine_threadsafe(manager.broadcast_json({
                "type": "YOUTUBE_STATUS",
                "payload": {"task_id": download_task_id, "status": "downloading", "message": f"æ­£åœ¨ä¸‹è¼‰: {url}"}
            }), loop)

            tool_script = "tools/mock_youtube_downloader.py" if IS_MOCK_MODE else "tools/youtube_downloader.py"
            cmd = [sys.executable, tool_script, "--url", url, "--output-dir", str(UPLOADS_DIR)]

            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8')

            last_line = ""
            if process.stdout:
                for line in iter(process.stdout.readline, ''):
                    line = line.strip()
                    if line:
                        last_line = line
                        # Optional: broadcast progress if the tool supports it
                        try:
                            progress_data = json.loads(line)
                            if progress_data.get("type") == "progress":
                                asyncio.run_coroutine_threadsafe(manager.broadcast_json({"type": "YOUTUBE_DOWNLOAD_PROGRESS", "payload": progress_data}), loop)
                        except json.JSONDecodeError:
                            pass # Ignore non-json lines

            process.wait()
            if process.returncode != 0:
                stderr_output = process.stderr.read() if process.stderr else "N/A"
                raise RuntimeError(f"YouTube downloader failed with exit code {process.returncode}: {stderr_output}")

            download_result = json.loads(last_line)
            # JULES: ä¿®æ­£æ­¤è™•çš„éµåï¼Œæ ¹æ“š downloader å·¥å…·çš„å¯¦éš›è¼¸å‡ºï¼Œæ‡‰ç‚º 'output_path'
            audio_file_path = download_result['output_path']
            video_title = download_result.get('video_title', 'ç„¡æ¨™é¡Œå½±ç‰‡') # å¾ä¸‹è¼‰çµæœä¸­ç²å–æ¨™é¡Œ

            db_client.update_task_status(download_task_id, 'completed', json.dumps(download_result))
            log.info(f"âœ… [åŸ·è¡Œç·’] YouTube éŸ³è¨Šä¸‹è¼‰å®Œæˆ: {audio_file_path}")

            # 2. è§¸ç™¼ AI è™•ç†
            # æ‰¾åˆ°ä¾è³´æ­¤ä¸‹è¼‰ä»»å‹™çš„è™•ç†ä»»å‹™
            dependent_task_id = db_client.find_dependent_task(download_task_id)
            if not dependent_task_id:
                raise ValueError(f"æ‰¾ä¸åˆ°ä¾è³´æ–¼ {download_task_id} çš„è™•ç†ä»»å‹™")

            process_task_info = db_client.get_task_status(dependent_task_id)
            process_payload = json.loads(process_task_info['payload'])
            model = process_payload['model']

            # é€šçŸ¥å‰ç«¯é–‹å§‹è™•ç†
            asyncio.run_coroutine_threadsafe(manager.broadcast_json({
                "type": "YOUTUBE_STATUS",
                "payload": {"task_id": dependent_task_id, "status": "processing", "message": f"ä½¿ç”¨ {model} é€²è¡Œ AI åˆ†æ..."}
            }), loop)

            tool_script = "tools/mock_gemini_processor.py" if IS_MOCK_MODE else "tools/gemini_processor.py"
            # JULES: ç¢ºä¿å‚³éçµ¦å·¥å…·çš„ output_dir æ˜¯ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„çš„
            report_output_dir = ROOT_DIR / "transcripts"
            report_output_dir.mkdir(exist_ok=True)

            cmd = [
                sys.executable,
                tool_script,
                "--audio-file", audio_file_path,
                "--model", model,
                "--output-dir", str(report_output_dir),
                "--video-title", video_title  # å°‡æ¨™é¡Œå‚³éçµ¦è™•ç†å™¨
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, check=True, encoding='utf-8')
            process_result = json.loads(result.stdout)

            db_client.update_task_status(dependent_task_id, 'completed', json.dumps(process_result))
            report_path = process_result.get("pdf_report_path") or process_result.get("html_report_path")
            log.info(f"âœ… [åŸ·è¡Œç·’] Gemini AI è™•ç†å®Œæˆã€‚å ±å‘Šä½æ–¼: {report_path}")

            # ç™¼é€æœ€çµ‚å®Œæˆè¨Šæ¯
            asyncio.run_coroutine_threadsafe(manager.broadcast_json({
                "type": "YOUTUBE_STATUS",
                "payload": {"task_id": dependent_task_id, "status": "completed", "result": process_result}
            }), loop)

        except Exception as e:
            log.error(f"âŒ [åŸ·è¡Œç·’] YouTube è™•ç†éˆä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            # ç¢ºå®šè¦æ›´æ–°å“ªå€‹ä»»å‹™ç‚ºå¤±æ•—ç‹€æ…‹
            failed_task_id = 'dependent_task_id' if 'dependent_task_id' in locals() else download_task_id
            db_client.update_task_status(failed_task_id, 'failed', json.dumps({"error": str(e)}))
            asyncio.run_coroutine_threadsafe(manager.broadcast_json({
                "type": "YOUTUBE_STATUS",
                "payload": {"task_id": failed_task_id, "status": "failed", "error": str(e)}
            }), loop)

    thread = threading.Thread(target=_process_in_thread)
    thread.start()


@app.websocket("/api/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            log.info(f"å¾ WebSocket æ”¶åˆ°è¨Šæ¯: {data}")

            try:
                message = json.loads(data)
                msg_type = message.get("type")
                payload = message.get("payload", {})

                if msg_type == "DOWNLOAD_MODEL":
                    model_size = payload.get("model")
                    if model_size:
                        log.info(f"æ”¶åˆ°ä¸‹è¼‰ '{model_size}' æ¨¡å‹çš„è«‹æ±‚ã€‚")
                        await manager.broadcast_json({
                            "type": "DOWNLOAD_STATUS",
                            "payload": {"model": model_size, "status": "starting", "progress": 0}
                        })
                        loop = asyncio.get_running_loop()
                        trigger_model_download(model_size, loop)
                    else:
                        await manager.broadcast_json({"type": "ERROR", "payload": "ç¼ºå°‘æ¨¡å‹å¤§å°åƒæ•¸"})

                elif msg_type == "START_TRANSCRIPTION":
                    task_id = payload.get("task_id")
                    if not task_id:
                        await manager.broadcast_json({"type": "ERROR", "payload": "ç¼ºå°‘ task_id åƒæ•¸"})
                        continue

                    task_info = db_client.get_task_status(task_id)
                    if not task_info:
                        await manager.broadcast_json({"type": "ERROR", "payload": f"æ‰¾ä¸åˆ°ä»»å‹™ {task_id}"})
                        continue

                    try:
                        task_payload = json.loads(task_info['payload'])
                        file_path = task_payload.get("input_file")
                        model_size = task_payload.get("model_size", "tiny")
                        language = task_payload.get("language")
                        beam_size = task_payload.get("beam_size", 5)
                    except (json.JSONDecodeError, KeyError) as e:
                        await manager.broadcast_json({"type": "ERROR", "payload": f"è§£æä»»å‹™ {task_id} çš„ payload å¤±æ•—: {e}"})
                        continue

                    if not file_path:
                        await manager.broadcast_json({"type": "ERROR", "payload": "ä»»å‹™ payload ä¸­ç¼ºå°‘æª”æ¡ˆè·¯å¾‘"})
                    else:
                        log.info(f"æ”¶åˆ°é–‹å§‹è½‰éŒ„ '{file_path}' çš„è«‹æ±‚ (ä¾†è‡ªä»»å‹™ {task_id})ã€‚")
                        loop = asyncio.get_running_loop()
                        trigger_transcription(task_id, file_path, model_size, language, beam_size, loop)

                elif msg_type == "START_YOUTUBE_PROCESSING":
                    task_id = payload.get("task_id") # This is the download_task_id
                    if not task_id:
                        await manager.broadcast_json({"type": "ERROR", "payload": "ç¼ºå°‘ task_id åƒæ•¸"})
                        continue

                    log.info(f"æ”¶åˆ°é–‹å§‹è™•ç† YouTube ä»»å‹™éˆçš„è«‹æ±‚ (èµ·å§‹ä»»å‹™ ID: {task_id})ã€‚")
                    loop = asyncio.get_running_loop()
                    trigger_youtube_processing(task_id, loop)

                else:
                    await manager.broadcast_json({
                        "type": "ECHO",
                        "payload": f"å·²æ”¶åˆ°æœªçŸ¥é¡å‹çš„è¨Šæ¯: {msg_type}"
                    })

            except json.JSONDecodeError:
                log.error("æ”¶åˆ°äº†é JSON æ ¼å¼çš„ WebSocket è¨Šæ¯ã€‚")
                await manager.broadcast_json({"type": "ERROR", "payload": "è¨Šæ¯å¿…é ˆæ˜¯ JSON æ ¼å¼"})

    except WebSocketDisconnect:
        manager.disconnect(websocket)
        log.info("WebSocket ç”¨æˆ¶ç«¯å·²é›¢ç·šã€‚")
    except Exception as e:
        log.error(f"WebSocket ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
        # ç¢ºä¿åœ¨ç™¼ç”ŸéŒ¯èª¤æ™‚ä¹Ÿä¸­æ–·é€£ç·š
        if websocket in manager.active_connections:
            manager.disconnect(websocket)


@app.get("/api/health")
async def health_check():
    """æä¾›ä¸€å€‹ç°¡å–®çš„å¥åº·æª¢æŸ¥ç«¯é»ã€‚"""
    return {"status": "ok", "message": "API Server is running."}


@app.post("/api/internal/notify_task_update", status_code=200)
async def notify_task_update(payload: Dict):
    """
    ä¸€å€‹å…§éƒ¨ç«¯é»ï¼Œä¾› Worker ç¨‹åºåœ¨ä»»å‹™å®Œæˆæ™‚å‘¼å«ï¼Œ
    ä»¥ä¾¿é€é WebSocket å°‡æ›´æ–°å»£æ’­çµ¦å‰ç«¯ã€‚
    """
    task_id = payload.get("task_id")
    status = payload.get("status")
    result = payload.get("result")
    log.info(f"ğŸ”” æ”¶åˆ°ä¾†è‡ª Worker çš„ä»»å‹™æ›´æ–°é€šçŸ¥: Task {task_id} -> {status}")

    # ç¢ºä¿ result æ˜¯å­—å…¸æ ¼å¼
    if isinstance(result, str):
        try:
            result = json.loads(result)
        except json.JSONDecodeError:
            log.warning(f"ä¾†è‡ª worker çš„ä»»å‹™ {task_id} çµæœä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ã€‚")

    message = {
        "type": "TRANSCRIPTION_STATUS",
        "payload": {
            "task_id": task_id,
            "status": status,
            "result": result
        }
    }
    await manager.broadcast_json(message)
    return {"status": "notification_sent"}


# --- ä¸»ç¨‹å¼å•Ÿå‹• ---
if __name__ == "__main__":
    import uvicorn
    import argparse

    parser = argparse.ArgumentParser(description="é³³å‡°éŸ³è¨Šè½‰éŒ„å„€ API ä¼ºæœå™¨")
    parser.add_argument(
        "--port",
        type=int,
        default=8001,
        help="ä¼ºæœå™¨ç›£è½çš„åŸ è™Ÿ"
    )
    args, _ = parser.parse_known_args()

    # JULES: ç§»é™¤æ­¤è™•çš„è³‡æ–™åº«åˆå§‹åŒ–å‘¼å«ã€‚
    # çˆ¶ç¨‹åº orchestrator.py å°‡æœƒè² è²¬æ­¤äº‹ï¼Œä»¥é¿å…ç«¶çˆ­æ¢ä»¶ã€‚

    # è¨­å®šè³‡æ–™åº«æ—¥èªŒ
    setup_database_logging()

    log.info("ğŸš€ å•Ÿå‹• API ä¼ºæœå™¨ (v3)...")
    log.info(f"è«‹åœ¨ç€è¦½å™¨ä¸­é–‹å•Ÿ http://127.0.0.1:{args.port}")
    uvicorn.run(app, host="0.0.0.0", port=args.port)
