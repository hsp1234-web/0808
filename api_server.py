# api_server.py
import argparse
import uuid
import shutil
import logging
import json
import subprocess
import sys
import threading
import asyncio
import os
import time
import re
from fastapi import FastAPI, UploadFile, File, Form, Request, HTTPException, WebSocket, WebSocketDisconnect, Query
from pydantic import BaseModel
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pathlib import Path
from typing import Optional, Dict, List

# Import genai safely
try:
    import google.generativeai as genai
except ImportError:
    genai = None

# åŒ¯å…¥æ–°çš„è³‡æ–™åº«å®¢æˆ¶ç«¯
from db.client import get_client

os.environ['TZ'] = 'Asia/Taipei'
if sys.platform != 'win32':
    time.tzset()

# --- æ¨¡å¼èˆ‡åŸ è™Ÿè¨­å®š ---
cli_parser = argparse.ArgumentParser()
cli_parser.add_argument("--mock", action="store_true", help="å•Ÿç”¨æ¨¡æ“¬æ¨¡å¼")
cli_parser.add_argument("--port", type=int, default=8001, help="æŒ‡å®šä¼ºæœå™¨ç›£è½çš„åŸ è™Ÿ")
cli_args, _ = cli_parser.parse_known_args()
IS_MOCK_MODE = cli_args.mock
PORT = cli_args.port

ROOT_DIR = Path(__file__).resolve().parent

# --- æ—¥èªŒè¨­å®š ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', handlers=[logging.StreamHandler()])
log = logging.getLogger('api_server')

def setup_database_logging():
    try:
        from db.log_handler import DatabaseLogHandler
        root_logger = logging.getLogger()
        if not any(isinstance(h, DatabaseLogHandler) for h in root_logger.handlers):
            root_logger.addHandler(DatabaseLogHandler(source='api_server'))
            log.info("è³‡æ–™åº«æ—¥èªŒè™•ç†å™¨è¨­å®šå®Œæˆ (source: api_server)ã€‚")
    except Exception as e:
        log.error(f"æ•´åˆè³‡æ–™åº«æ—¥èªŒæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)

# --- WebSocket é€£ç·šç®¡ç†å™¨ ---
class ConnectionManager:
    def __init__(self):
        self.active_connections: list[WebSocket] = []
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
    async def broadcast_json(self, data: dict):
        for connection in self.active_connections:
            await connection.send_json(data)

manager = ConnectionManager()
db_client = get_client()

# --- Pydantic æ¨¡å‹ ---
class YouTubeProcessRequest(BaseModel):
    urls: List[str]
    model: str

app = FastAPI(title="é³³å‡°éŸ³è¨Šè½‰éŒ„å„€ API (v3 - é‡æ§‹)", version="3.0")
UPLOADS_DIR = ROOT_DIR / "uploads"
STATIC_DIR = ROOT_DIR / "static"
UPLOADS_DIR.mkdir(exist_ok=True)
if STATIC_DIR.exists():
    app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# --- API Endpoints ---
@app.get("/", response_class=HTMLResponse)
async def serve_frontend():
    html_file_path = STATIC_DIR / "mp3.html"
    if not html_file_path.is_file():
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°å‰ç«¯ä»‹é¢æª”æ¡ˆ (mp3.html)")
    return HTMLResponse(content=html_file_path.read_text(encoding="utf-8"), status_code=200)

@app.get("/api/key_status")
async def get_key_status():
    api_key = os.getenv("GOOGLE_API_KEY")
    return {"is_configured": bool(api_key)}

def get_model_version_score(api_name_lower):
    score = 9999
    if "latest" in api_name_lower: score = 0
    elif "preview" in api_name_lower: score = 1000
    return score

def sort_models_for_dropdown_key(model_api_name):
    name_lower = model_api_name.lower()
    if "gemini-1.5-flash" in name_lower: priority_group = 0
    elif "gemini-1.5-pro" in name_lower: priority_group = 1
    else: priority_group = 2
    return (priority_group, get_model_version_score(name_lower), name_lower)

@app.get("/api/models")
async def get_models():
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return JSONResponse(content=[])
    if not genai:
         raise HTTPException(status_code=500, detail="google-generativeai å¥—ä»¶æœªå®‰è£")
    try:
        genai.configure(api_key=api_key)
        models_from_api = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods and ('flash' in m.name or 'pro' in m.name):
                 models_from_api.append({"display_name": m.display_name, "api_name": m.name})
        models_from_api.sort(key=lambda item: sort_models_for_dropdown_key(item['api_name']))
        return JSONResponse(content=models_from_api)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç²å–æ¨¡å‹åˆ—è¡¨å¤±æ•—: {e}")

@app.post("/api/process_youtube", status_code=202)
async def process_youtube_url(request: YouTubeProcessRequest):
    tasks_created = []
    for url in request.urls:
        task_id = str(uuid.uuid4())
        payload = {"url": url, "model": request.model}
        db_client.add_task(task_id, json.dumps(payload), task_type='youtube_process')
        tasks_created.append({"task_id": task_id, "url": url, "model": request.model})
    return JSONResponse(content={"message": f"å·²ç‚º {len(tasks_created)} å€‹ URL æˆåŠŸå»ºç«‹ä»»å‹™ã€‚", "tasks": tasks_created}, status_code=202)

def trigger_youtube_processing(task_id: str, url: str, model: str, loop: asyncio.AbstractEventLoop):
    def _process_in_thread():
        log.info(f"ğŸ§µ [åŸ·è¡Œç·’] é–‹å§‹è™•ç† YouTube ä»»å‹™: {task_id}ï¼ŒURL: {url}")

        def log_stderr(pipe, pipe_name):
            """åœ¨å–®ç¨çš„åŸ·è¡Œç·’ä¸­è®€å–ä¸¦è¨˜éŒ„å­ç¨‹åºçš„ stderrã€‚"""
            for line in iter(pipe.readline, ''):
                log.info(f"[{pipe_name} stderr] {line.strip()}")
            pipe.close()

        try:
            downloader_script = "tools/mock_youtube_downloader.py" if IS_MOCK_MODE else "tools/youtube_downloader.py"
            downloader_cmd = [sys.executable, downloader_script, f"--url={url}", f"--output-dir={str(UPLOADS_DIR)}"]
            process = subprocess.Popen(downloader_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8')

            # å•Ÿå‹•ä¸€å€‹åŸ·è¡Œç·’ä¾†éåŒæ­¥è®€å–ä¸‹è¼‰å™¨çš„ stderr
            stderr_thread = threading.Thread(target=log_stderr, args=(process.stderr, "Downloader"))
            stderr_thread.start()

            asyncio.run_coroutine_threadsafe(manager.broadcast_json({"type": "YOUTUBE_PROCESS_STATUS", "payload": {"task_id": task_id, "status": "downloading", "detail": "Starting download..."}}), loop)

            downloaded_audio_path = None
            video_title = "Untitled"
            for line in iter(process.stdout.readline, ''):
                data = json.loads(line.strip())
                if data.get("type") == "progress":
                    asyncio.run_coroutine_threadsafe(manager.broadcast_json({"type": "YOUTUBE_DOWNLOAD_PROGRESS", "payload": {"task_id": task_id, **data}}), loop)
                elif data.get("type") == "result":
                    if data.get("status") == "completed":
                        downloaded_audio_path = data.get("output_path")
                        video_title = data.get("video_title", video_title)
                    else:
                        # ç­‰å¾… stderr åŸ·è¡Œç·’çµæŸï¼Œä»¥ç¢ºä¿æ‰€æœ‰æ—¥èªŒéƒ½å·²æ“·å–
                        process.wait()
                        stderr_thread.join()
                        raise RuntimeError(f"Downloader failed: {data.get('error', 'Unknown error')}")

            if not downloaded_audio_path:
                raise RuntimeError("Downloader did not provide output path.")

            processor_script = "tools/mock_gemini_processor.py" if IS_MOCK_MODE else "tools/gemini_processor.py"
            asyncio.run_coroutine_threadsafe(manager.broadcast_json({"type": "YOUTUBE_PROCESS_STATUS", "payload": {"task_id": task_id, "status": "processing", "detail": "AI is processing the audio..."}}), loop)

            processor_cmd = [sys.executable, processor_script, f"--audio-file={downloaded_audio_path}", f"--model={model}", f"--video-title={video_title}", f"--output-dir={str(UPLOADS_DIR)}"]
            proc_env = os.environ.copy()
            api_key = os.getenv("GOOGLE_API_KEY")
            if not api_key:
                raise RuntimeError("API é‡‘é‘°æœªè¨­å®šã€‚")
            proc_env["GOOGLE_API_KEY"] = api_key

            proc_gemini = subprocess.Popen(processor_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8', env=proc_env)

            # å•Ÿå‹•ä¸€å€‹åŸ·è¡Œç·’ä¾†éåŒæ­¥è®€å– Gemini è™•ç†å™¨çš„ stderr
            gemini_stderr_thread = threading.Thread(target=log_stderr, args=(proc_gemini.stderr, "GeminiProcessor"))
            gemini_stderr_thread.start()

            html_report_path = None
            for line in iter(proc_gemini.stdout.readline, ''):
                data = json.loads(line.strip())
                if data.get("type") == "progress":
                    asyncio.run_coroutine_threadsafe(manager.broadcast_json({"type": "YOUTUBE_PROCESS_STATUS", "payload": {"task_id": task_id, "status": "processing", "detail": data.get("detail")}}), loop)
                elif data.get("type") == "result" and data.get("status") == "completed":
                    html_report_path = data.get("html_report_path")

            if not html_report_path:
                raise RuntimeError("Gemini processor did not provide output path.")

            web_accessible_path = f"/uploads/{Path(html_report_path).name}"
            final_result_obj = {"downloaded_audio_path": str(downloaded_audio_path), "html_report_path": web_accessible_path, "video_title": video_title}
            db_client.update_task_status(task_id, 'completed', json.dumps(final_result_obj))

            asyncio.run_coroutine_threadsafe(manager.broadcast_json({"type": "YOUTUBE_PROCESS_STATUS", "payload": {"task_id": task_id, "status": "completed", "result": final_result_obj}}), loop)
        except Exception as e:
            error_message = f"ä»»å‹™åŸ·è¡Œç·’ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}"
            log.error(f"âŒ [åŸ·è¡Œç·’] YouTube è™•ç†ä»»å‹™ '{task_id}' å¤±æ•—: {error_message}", exc_info=True)

            # å°‡éŒ¯èª¤è³‡è¨Šè¨˜éŒ„åˆ°è³‡æ–™åº«ï¼Œé€™æ˜¯è®“ç³»çµ±è¿”å› IDLE ç‹€æ…‹çš„é—œéµ
            error_payload = {"error": error_message}
            db_client.update_task_status(task_id, 'failed', json.dumps(error_payload))

            # é€é WebSocket é€šçŸ¥å‰ç«¯å¤±æ•—
            asyncio.run_coroutine_threadsafe(
                manager.broadcast_json({
                    "type": "YOUTUBE_PROCESS_STATUS",
                    "payload": {"task_id": task_id, "status": "failed", "error": error_message}
                }),
                loop
            )

    thread = threading.Thread(target=_process_in_thread)
    thread.start()

@app.websocket("/api/ws")
async def websocket_endpoint(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            msg_type = message.get("type")
            payload = message.get("payload", {})
            if msg_type == "START_YOUTUBE_PROCESSING":
                task_id = payload.get("task_id")
                task_info = db_client.get_task_status(task_id)
                if task_info:
                    task_payload = json.loads(task_info['payload'])
                    loop = asyncio.get_running_loop()
                    trigger_youtube_processing(task_id, task_payload.get("url"), task_payload.get("model"), loop)
    except WebSocketDisconnect:
        manager.disconnect(websocket)
    except Exception as e:
        log.error(f"WebSocket ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)

# Other endpoints like /api/status/{task_id}, etc. are omitted for brevity but assumed to be here.

if __name__ == "__main__":
    import uvicorn
    setup_database_logging()
    log.info(f"ğŸš€ å•Ÿå‹• API ä¼ºæœå™¨ (v3)æ–¼åŸ è™Ÿ {PORT}...")
    uvicorn.run(app, host="0.0.0.0", port=PORT)
