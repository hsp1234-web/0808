# -*- coding: utf-8 -*-
# tools/gemini_processor.py
import argparse
import json
import logging
import os
import re
import sys
import time
from pathlib import Path

# --- æ—¥èªŒè¨­å®š ---
# JULES'S FIX: Redirect all logging to stderr to keep stdout clean for the final JSON result.
# This is crucial to prevent JSONDecodeError in the parent process (api_server.py).
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    # å°‡æ—¥èªŒå’Œé€²åº¦è¨Šæ¯å°å‘æ¨™æº–éŒ¯èª¤æµ
    stream=sys.stderr
)
log = logging.getLogger('gemini_processor_tool')

# --- è¼”åŠ©å‡½å¼ (ä¾†è‡ª damo.py) ---
def sanitize_filename(title: str, max_len: int = 60) -> str:
    """æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤ç„¡æ•ˆå­—å…ƒä¸¦å–ä»£ç©ºæ ¼ã€‚"""
    if not title:
        title = "untitled_document"
    # ç§»é™¤éæ³•å­—å…ƒ
    title = re.sub(r'[\\/*?:"<>|]', "_", title)
    title = title.replace(" ", "_")
    # å°‡å¤šå€‹åº•ç·šç¸®æ¸›ç‚ºä¸€å€‹
    title = re.sub(r"_+", "_", title)
    # å»é™¤é–‹é ­å’Œçµå°¾çš„åº•ç·š
    title = title.strip('_')
    return title[:max_len]

def print_progress(status: str, detail: str, extra_data: dict = None):
    """
    JULES'S FIX: ä»¥æ¨™æº– JSON æ ¼å¼è¼¸å‡ºé€²åº¦åˆ° stderrã€‚
    é€™ç¢ºä¿äº† stdout ä¿æŒä¹¾æ·¨ï¼Œåªç”¨æ–¼å‚³éæœ€çµ‚çµæœã€‚
    """
    progress_data = {
        "type": "progress",
        "status": status,
        "detail": detail
    }
    if extra_data:
        progress_data.update(extra_data)
    # å°‡é€²åº¦è¨Šæ¯è¼¸å‡ºåˆ° stderr
    print(json.dumps(progress_data), file=sys.stderr, flush=True)

# --- æç¤ºè©ç®¡ç† ---
# å–å¾—æ­¤æª”æ¡ˆæ‰€åœ¨çš„ç›®éŒ„ï¼Œä¸¦å»ºç«‹ prompts.json çš„è·¯å¾‘
PROMPTS_FILE_PATH = Path(__file__).resolve().parent.parent / "prompts" / "default_prompts.json"

def load_prompts() -> dict:
    """å¾ prompts/default_prompts.json è¼‰å…¥æ‰€æœ‰æç¤ºè©ã€‚"""
    try:
        with open(PROMPTS_FILE_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        log.critical(f"ğŸ”´ ç„¡æ³•è¼‰å…¥æˆ–è§£ææç¤ºè©æª”æ¡ˆ: {PROMPTS_FILE_PATH}ã€‚éŒ¯èª¤: {e}", exc_info=True)
        # åœ¨ç„¡æ³•è¼‰å…¥æç¤ºè©æ™‚ï¼Œç³»çµ±ç„¡æ³•é‹ä½œï¼Œæ‡‰ç›´æ¥é€€å‡º
        sys.exit(1)

# åœ¨æ¨¡çµ„è¼‰å…¥æ™‚å°±è®€å–æ‰€æœ‰æç¤ºè©
ALL_PROMPTS = load_prompts()


import google.generativeai as genai

# å•é¡Œå››ï¼šå®šç¾©éŒ¯èª¤è½‰è­¯å°ç…§è¡¨
GEMINI_ERROR_MAP = {
    "SAFETY": "è™•ç†å¤±æ•—ï¼šå…§å®¹å¯èƒ½æ¶‰åŠå®‰å…¨æˆ–æ•æ„Ÿè­°é¡Œã€‚",
    "RECITATION": "è™•ç†å¤±æ•—ï¼šå…§å®¹å¯èƒ½å¼•ç”¨äº†å—ç‰ˆæ¬Šä¿è­·çš„è³‡æ–™ã€‚",
    "OTHER": "è™•ç†å¤±æ•—ï¼šå› æœªçŸ¥çš„æ¨¡å‹å…§éƒ¨åŸå› çµ‚æ­¢ã€‚"
}

def get_error_message_from_response(response):
    """å¾ Gemini API å›æ‡‰ä¸­è§£æå‡ºä½¿ç”¨è€…æ˜“æ–¼ç†è§£çš„éŒ¯èª¤è¨Šæ¯ã€‚"""
    try:
        # å„ªå…ˆæª¢æŸ¥æ˜¯å¦æœ‰æ˜ç¢ºçš„é˜»æ“‹åŸå› 
        if response.prompt_feedback.block_reason:
            reason = response.prompt_feedback.block_reason.name
            return GEMINI_ERROR_MAP.get(reason, f"è«‹æ±‚è¢«æœªçŸ¥åŸå› é˜»æ“‹: {reason}")

        # æ¥è‘—æª¢æŸ¥å€™é¸å…§å®¹çš„å®ŒæˆåŸå› æ˜¯å¦æ­£å¸¸
        candidate = response.candidates[0]
        if candidate.finish_reason.name not in ("STOP", "MAX_TOKENS"):
            reason = candidate.finish_reason.name
            return GEMINI_ERROR_MAP.get(reason, f"è™•ç†ç•°å¸¸çµ‚æ­¢: {reason}")
    except (AttributeError, IndexError):
        # å¦‚æœå›æ‡‰çš„çµæ§‹ä¸ç¬¦åˆé æœŸï¼Œå‰‡ä¸é€²è¡Œè™•ç†
        return None
    return None

# --- æ ¸å¿ƒ Gemini è™•ç†å‡½å¼ ---

def list_models():
    """åˆ—å‡ºå¯ç”¨çš„ Gemini æ¨¡å‹ä¸¦ä»¥ JSON æ ¼å¼è¼¸å‡ºã€‚"""
    try:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable not set.")
        genai.configure(api_key=api_key)

        models_list = []
        for m in genai.list_models():
            # æˆ‘å€‘åªé—œå¿ƒæ”¯æ´ 'generateContent' ä¸”å¯ç”¨æ–¼ 'models/' çš„æ¨¡å‹
            if 'generateContent' in m.supported_generation_methods:
                # ç°¡åŒ–è¼¸å‡ºï¼ŒåªåŒ…å«åç¨±å’Œé¡¯ç¤ºåç¨±
                 models_list.append({
                     "id": m.name,
                     "name": m.display_name
                 })
        print(json.dumps(models_list), flush=True)
    except Exception as e:
        log.critical(f"ğŸ”´ Failed to list models: {e}", exc_info=True)
        # å°‡éŒ¯èª¤è¨Šæ¯è¼¸å‡ºåˆ° stderrï¼Œä»¥ä¾¿çˆ¶ç¨‹åºæ“·å–
        print(f"Error listing models: {e}", file=sys.stderr, flush=True)
        sys.exit(1)

def validate_key():
    """
    åƒ…é©—è­‰ API é‡‘é‘°çš„æœ‰æ•ˆæ€§ã€‚
    é€éä¸€å€‹è¼•é‡ç´šçš„æ“ä½œï¼ˆå¦‚åˆ—å‡ºæ¨¡å‹ï¼‰ä¾†å¯¦ç¾ã€‚
    å¦‚æœæˆåŠŸï¼Œä»¥ exit code 0 é€€å‡ºã€‚
    å¦‚æœå¤±æ•—ï¼Œä»¥ non-zero exit code é€€å‡ºï¼Œä¸¦åœ¨ stderr ä¸­æä¾›éŒ¯èª¤è¨Šæ¯ã€‚
    """
    try:
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY environment variable not set.")
        genai.configure(api_key=api_key)

        # list_models æ˜¯ä¸€å€‹ç›¸å°è¼•é‡ç´šçš„é©—è­‰æ“ä½œ
        genai.list_models()
        log.info("âœ… API key validation successful.")
        sys.exit(0)
    except Exception as e:
        # å°‡å…·é«”çš„éŒ¯èª¤è¨Šæ¯è¼¸å‡ºåˆ° stderr
        # Google API éŒ¯èª¤é€šå¸¸æœ‰è‡ªå·±çš„è©³ç´°æè¿°
        print(f"API key not valid. Reason: {e}", file=sys.stderr, flush=True)
        sys.exit(1)


def upload_to_gemini(genai_module, audio_path: Path, display_filename: str):
    """ä¸Šå‚³æª”æ¡ˆè‡³ Gemini Files APIã€‚"""
    log.info(f"â˜ï¸ Uploading '{display_filename}' to Gemini Files API...")
    print_progress("uploading", f"æ­£åœ¨ä¸Šå‚³éŸ³è¨Šæª”æ¡ˆ {display_filename}...")
    try:
        # åµæ¸¬ MIME é¡å‹
        ext = audio_path.suffix.lower()
        mime_map = {'.mp3': 'audio/mp3', '.m4a': 'audio/m4a', '.aac': 'audio/aac',
                    '.wav': 'audio/wav', '.ogg': 'audio/ogg', '.flac': 'audio/flac',
                    '.webm': 'audio/webm', '.mp4': 'audio/mp4'}
        mime_type = mime_map.get(ext, 'application/octet-stream')
        if mime_type in ['audio/m4a', 'audio/mp4']:
            mime_type = 'audio/aac' # Gemini åå¥½ aac

        audio_file_resource = genai_module.upload_file(
            path=str(audio_path),
            display_name=display_filename,
            mime_type=mime_type
        )
        log.info(f"âœ… Upload successful. Gemini File URI: {audio_file_resource.uri}")
        print_progress("upload_complete", "éŸ³è¨Šä¸Šå‚³æˆåŠŸã€‚")
        return audio_file_resource
    except Exception as e:
        log.critical(f"ğŸ”´ Failed to upload file to Gemini: {e}", exc_info=True)
        raise

def get_summary_and_transcript(genai_module, gemini_file_resource, model_api_name: str, video_title: str, original_filename: str):
    """
    ä½¿ç”¨ Gemini æ¨¡å‹ç”Ÿæˆæ‘˜è¦èˆ‡é€å­—ç¨¿ã€‚
    JULES'S UPDATE: Now returns the full response object for token counting.
    """
    log.info(f"ğŸ¤– Requesting summary and transcript from model '{model_api_name}'...")
    print_progress("generating_transcript", "AI æ­£åœ¨ç”Ÿæˆæ‘˜è¦èˆ‡é€å­—ç¨¿...")
    prompt = ALL_PROMPTS['get_summary_and_transcript'].format(original_filename=original_filename, video_title=video_title)
    try:
        model = genai_module.GenerativeModel(model_api_name)
        response = model.generate_content([prompt, gemini_file_resource], request_options={'timeout': 3600})
        full_response_text = response.text

        summary_match = re.search(r"\[é‡é»æ‘˜è¦é–‹å§‹\](.*?)\[é‡é»æ‘˜è¦çµæŸ\]", full_response_text, re.DOTALL)
        summary_text = summary_match.group(1).strip() if summary_match else "æœªæ“·å–åˆ°é‡é»æ‘˜è¦ã€‚"

        transcript_match = re.search(r"\[è©³ç´°é€å­—ç¨¿é–‹å§‹\](.*?)\[è©³ç´°é€å­—ç¨¿çµæŸ\]", full_response_text, re.DOTALL)
        transcript_text = transcript_match.group(1).strip() if transcript_match else "æœªæ“·å–åˆ°è©³ç´°é€å­—ç¨¿ã€‚"

        if "æœªæ“·å–åˆ°" in summary_text and "æœªæ“·å–åˆ°" in transcript_text and "---[é€å­—ç¨¿åˆ†éš”ç·š]---" not in full_response_text:
            transcript_text = full_response_text
            summary_text = "ï¼ˆè‡ªå‹•æ‘˜è¦å¤±æ•—ï¼Œè«‹åƒè€ƒä¸‹æ–¹é€å­—ç¨¿è‡ªè¡Œæ•´ç†ï¼‰"

        log.info("âœ… Successfully generated summary and transcript.")
        print_progress("transcript_generated", "æ‘˜è¦èˆ‡é€å­—ç¨¿ç”Ÿæˆå®Œç•¢ã€‚")
        return summary_text, transcript_text, response
    except Exception as e:
        log.critical(f"ğŸ”´ Failed to get summary/transcript from Gemini: {e}", exc_info=True)
        raise

def generate_html_report(genai_module, summary_text: str, transcript_text: str, model_api_name: str, video_title: str):
    """
    ä½¿ç”¨ Gemini æ¨¡å‹ç”Ÿæˆ HTML å ±å‘Šã€‚
    JULES'S UPDATE: Now returns the full response object for token counting.
    """
    log.info(f"ğŸ¨ Requesting HTML report from model '{model_api_name}'...")
    print_progress("generating_html", "AI æ­£åœ¨ç¾åŒ–æ ¼å¼ä¸¦ç”Ÿæˆ HTML å ±å‘Š...")
    prompt = ALL_PROMPTS['format_as_html'].format(
        video_title_for_html=video_title,
        summary_text_for_html=summary_text,
        transcript_text_for_html=transcript_text
    )
    try:
        model = genai_module.GenerativeModel(model_api_name)
        response = model.generate_content(prompt, request_options={'timeout': 1800})
        generated_html = response.text

        if generated_html.strip().startswith("```html"):
            generated_html = generated_html.strip()[7:]
        if generated_html.strip().endswith("```"):
            generated_html = generated_html.strip()[:-3]

        doctype_pos = generated_html.lower().find("<!doctype html>")
        if doctype_pos != -1:
            generated_html = generated_html[doctype_pos:]

        log.info("âœ… Successfully generated HTML report.")
        print_progress("html_generated", "HTML å ±å‘Šç”Ÿæˆå®Œç•¢ã€‚")
        return generated_html.strip(), response
    except Exception as e:
        log.critical(f"ğŸ”´ Failed to generate HTML report from Gemini: {e}", exc_info=True)
        raise

def process_audio_file(audio_path: Path, model: str, video_title: str, output_dir: Path, tasks: str, output_format: str):
    """
    å…¨æ–°çš„å½ˆæ€§è™•ç†æµç¨‹ï¼Œæ ¹æ“šå‚³å…¥çš„ tasks å’Œ output_format åŸ·è¡Œæ“ä½œã€‚
    JULES'S UPDATE: Added timing, token counting, and robust error handling.
    """
    start_time = time.time()
    total_tokens_used = 0

    try:
        import google.generativeai as genai
    except ImportError:
        log.critical("ğŸ”´ Necessary library (google-generativeai) not installed.")
        raise

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY environment variable not set.")
    genai.configure(api_key=api_key)

    task_list = [t.strip() for t in tasks.lower().split(',') if t.strip()]
    results = {}

    gemini_file_resource = None
    try:
        gemini_file_resource = upload_to_gemini(genai, audio_path, audio_path.name)
        model_instance = genai.GenerativeModel(model)

        def get_token_count(response):
            try:
                return response.usage_metadata.total_token_count
            except (AttributeError, ValueError):
                return 0

        # --- åŸ·è¡Œ AI ä»»å‹™ ---
        if "summary" in task_list and "transcript" in task_list:
            log.info("åŸ·è¡Œä»»å‹™: æ‘˜è¦èˆ‡é€å­—ç¨¿ (åˆä½µåŸ·è¡Œ)")
            summary, transcript, response = get_summary_and_transcript(genai, gemini_file_resource, model, video_title, audio_path.name)
            error_msg = get_error_message_from_response(response)
            if error_msg: raise ValueError(error_msg)
            total_tokens_used += get_token_count(response)
            results['summary'] = summary
            results['transcript'] = transcript
        else:
            if "summary" in task_list:
                log.info("åŸ·è¡Œä»»å‹™: åƒ…æ‘˜è¦")
                prompt = ALL_PROMPTS['get_summary_only'].format(original_filename=audio_path.name, video_title=video_title)
                response = model_instance.generate_content([prompt, gemini_file_resource], request_options={'timeout': 1800})
                error_msg = get_error_message_from_response(response)
                if error_msg: raise ValueError(error_msg)
                total_tokens_used += get_token_count(response)
                results['summary'] = response.text.strip()
                log.info("âœ… æ‘˜è¦å®Œæˆ")

            if "transcript" in task_list:
                log.info("åŸ·è¡Œä»»å‹™: åƒ…é€å­—ç¨¿")
                prompt = ALL_PROMPTS['get_transcript_only'].format(original_filename=audio_path.name, video_title=video_title)
                response = model_instance.generate_content([prompt, gemini_file_resource], request_options={'timeout': 3600})
                error_msg = get_error_message_from_response(response)
                if error_msg: raise ValueError(error_msg)
                total_tokens_used += get_token_count(response)
                results['transcript'] = response.text.strip()
                log.info("âœ… é€å­—ç¨¿å®Œæˆ")

        if "translate" in task_list:
            log.info("åŸ·è¡Œä»»å‹™: ç¿»è­¯")
            text_to_translate = results.get('transcript', results.get('summary', ''))
            if text_to_translate:
                prompt = ALL_PROMPTS['translate_text'].format(text_to_translate=text_to_translate)
                response = model_instance.generate_content(prompt, request_options={'timeout': 1800})
                error_msg = get_error_message_from_response(response)
                if error_msg: raise ValueError(error_msg)
                total_tokens_used += get_token_count(response)
                results['translation'] = response.text.strip()
                log.info("âœ… ç¿»è­¯å®Œæˆ")
            else:
                log.warning("âš ï¸ ç„¡æ³•åŸ·è¡Œç¿»è­¯ï¼Œå› ç‚ºæ²’æœ‰å¯ä¾›ç¿»è­¯çš„å…§å®¹ã€‚")

        if "translate_zh" in task_list:
            log.info("åŸ·è¡Œä»»å‹™: ç¿»è­¯æˆç¹é«”ä¸­æ–‡")
            text_to_translate = results.get('transcript', results.get('summary', ''))
            if text_to_translate:
                prompt = ALL_PROMPTS['translate_text_zh'].format(text_to_translate=text_to_translate)
                response = model_instance.generate_content(prompt, request_options={'timeout': 1800})
                error_msg = get_error_message_from_response(response)
                if error_msg: raise ValueError(error_msg)
                total_tokens_used += get_token_count(response)
                results['translation_zh'] = response.text.strip()
                log.info("âœ… ç¿»è­¯æˆç¹é«”ä¸­æ–‡å®Œæˆ")
            else:
                log.warning("âš ï¸ ç„¡æ³•åŸ·è¡Œç¹é«”ä¸­æ–‡ç¿»è­¯ï¼Œå› ç‚ºæ²’æœ‰å¯ä¾›ç¿»è­¯çš„å…§å®¹ã€‚")

        # --- æ ¼å¼åŒ–èˆ‡å„²å­˜ ---
        sanitized_title = sanitize_filename(video_title)
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        final_filename_base = f"{sanitized_title}_{timestamp}_AI_Report"
        output_path = None

        if output_format == 'html':
            log.info("ç”Ÿæˆ HTML æ ¼å¼å ±å‘Š...")
            summary_content = results.get('summary', 'ç„¡æ‘˜è¦')
            transcript_content = results.get('transcript', 'ç„¡é€å­—ç¨¿')
            html_content, response = generate_html_report(genai, summary_content, transcript_content, model, video_title)
            error_msg = get_error_message_from_response(response)
            if error_msg: raise ValueError(error_msg)
            total_tokens_used += get_token_count(response)
            output_path = output_dir / f"{final_filename_base}.html"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(html_content)
            log.info(f"âœ… HTML å ±å‘Šå·²å„²å­˜: {output_path}")

        elif output_format == 'txt':
            log.info("ç”Ÿæˆ TXT æ ¼å¼å ±å‘Š...")
            output_content = f"å ±å‘Šæ¨™é¡Œ: {video_title}\n\n"
            if 'summary' in results:
                output_content += f"--- é‡é»æ‘˜è¦ ---\n{results['summary']}\n\n"
            if 'transcript' in results:
                output_content += f"--- è©³ç´°é€å­—ç¨¿ ---\n{results['transcript']}\n\n"
            if 'translation' in results:
                output_content += f"--- ä½¿ç”¨åŸæ–‡ ---\n{results['translation']}\n\n"
            if 'translation_zh' in results:
                output_content += f"--- ç¹é«”ä¸­æ–‡ç¿»è­¯ ---\n{results['translation_zh']}\n\n"
            output_path = output_dir / f"{final_filename_base}.txt"
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(output_content)
            log.info(f"âœ… TXT å ±å‘Šå·²å„²å­˜: {output_path}")
        else:
             raise ValueError(f"ä¸æ”¯æ´çš„è¼¸å‡ºæ ¼å¼: {output_format}")

        processing_duration = time.time() - start_time

        final_result = {
            "type": "result",
            "status": "completed",
            "output_path": str(output_path),
            "video_title": video_title,
            "total_tokens_used": total_tokens_used,
            "processing_duration_seconds": round(processing_duration, 2)
        }
        print(json.dumps(final_result), flush=True)

    except ValueError as e:
        # æ•æ‰æˆ‘å€‘è‡ªè¨‚çš„ã€æ˜“æ–¼ç†è§£çš„éŒ¯èª¤
        log.error(f"âŒ Gemini è™•ç†å¤±æ•—: {e}")
        raise # é‡æ–°æ‹‹å‡ºï¼Œç”±ä¸» exce-pt å€å¡Šè™•ç† JSON è¼¸å‡º
    except Exception as e:
        log.critical(f"ğŸ”´ è™•ç†æµç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„åš´é‡éŒ¯èª¤: {e}", exc_info=True)
        raise

    finally:
        if gemini_file_resource:
            log.info(f"ğŸ—‘ï¸ Cleaning up Gemini file: {gemini_file_resource.name}")
            try:
                for attempt in range(3):
                    try:
                        genai.delete_file(gemini_file_resource.name)
                        log.info("âœ… Cleanup successful.")
                        break
                    except Exception as e_del:
                        log.warning(f"Attempt {attempt+1} to delete file failed: {e_del}")
                        if attempt < 2:
                            time.sleep(2)
                        else:
                            raise
            except Exception as e:
                log.error(f"ğŸ”´ Failed to clean up Gemini file '{gemini_file_resource.name}' after retries: {e}")


def main():
    parser = argparse.ArgumentParser(description="Gemini AI è™•ç†å·¥å…·ã€‚")
    parser.add_argument(
        "--command",
        type=str,
        default="process",
        choices=["process", "list_models", "validate_key"],
        help="è¦åŸ·è¡Œçš„æ“ä½œã€‚"
    )
    # æ ¹æ“šæŒ‡ä»¤ï¼Œå‹•æ…‹æ±ºå®šå…¶ä»–åƒæ•¸æ˜¯å¦ç‚ºå¿…éœ€
    # æˆ‘å€‘å…ˆè§£æä¸€æ¬¡ï¼Œçœ‹çœ‹æŒ‡ä»¤æ˜¯ä»€éº¼
    args, remaining_argv = parser.parse_known_args()

    if args.command == "list_models":
        list_models()
        return

    if args.command == "validate_key":
        validate_key()
        return

    # å¦‚æœæ˜¯ 'process' æŒ‡ä»¤ï¼Œå‰‡éœ€è¦å…¶ä»–åƒæ•¸
    if args.command == "process":
        process_parser = argparse.ArgumentParser()
        process_parser.add_argument("--command", type=str, help=argparse.SUPPRESS) # å¿½ç•¥å·²è§£æçš„ command
        process_parser.add_argument("--audio-file", type=str, required=True, help="è¦è™•ç†çš„éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ã€‚")
        process_parser.add_argument("--model", type=str, required=True, help="è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹ API åç¨±ã€‚")
        process_parser.add_argument("--video-title", type=str, required=True, help="åŸå§‹å½±ç‰‡æ¨™é¡Œï¼Œç”¨æ–¼æç¤ºè©ã€‚")
        process_parser.add_argument("--output-dir", type=str, required=True, help="å„²å­˜ç”Ÿæˆå ±å‘Šçš„ç›®éŒ„ã€‚")
        # --- æ–°å¢çš„å½ˆæ€§åƒæ•¸ ---
        process_parser.add_argument("--tasks", type=str, default="summary,transcript", help="è¦åŸ·è¡Œçš„ä»»å‹™åˆ—è¡¨ï¼Œä»¥é€—è™Ÿåˆ†éš”ã€‚ä¾‹å¦‚ï¼š'summary,transcript,translate'")
        process_parser.add_argument("--output-format", type=str, default="html", choices=["html", "txt"], help="æœ€çµ‚è¼¸å‡ºçš„æª”æ¡ˆæ ¼å¼ã€‚")


        process_args = process_parser.parse_args(remaining_argv)

        audio_path = Path(process_args.audio_file)
        output_path = Path(process_args.output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        if not audio_path.exists():
            log.critical(f"Input audio file not found: {audio_path}")
            print(json.dumps({"type": "result", "status": "failed", "error": f"Input file not found: {audio_path}"}), flush=True)
            sys.exit(1)

        try:
            # å°‡æ–°çš„åƒæ•¸å‚³éçµ¦ process_audio_file
            process_audio_file(
                audio_path=audio_path,
                model=process_args.model,
                video_title=process_args.video_title,
                output_dir=output_path,
                tasks=process_args.tasks,
                output_format=process_args.output_format
            )
        except Exception as e:
            log.critical(f"An error occurred in the main processing flow: {e}", exc_info=True)
            print(json.dumps({"type": "result", "status": "failed", "error": str(e)}), flush=True)
            sys.exit(1)


if __name__ == "__main__":
    main()
