# AI 驅動品質保證體系轉型之彙總報告

## 緒論：由混沌至澄明之探索性歷程

於專案歷經重大之架構性重構後，品質保證體系面臨了嚴峻之危機。傳統之端對端測試協議，不僅在執行效率上顯現其低下性，更於視覺化驗證層面暴露出顯著之盲點，從而對開發進程構成實質性之阻礙。本報告旨在彙總此一探索性過程，詳述如何透過與人工智慧助理之深度協同，最終擘劃出一套具革命性意義、由人工智慧所驅動之快速失效測試策略。

## 核心困境與演化過程

初始之困境可被明確界定為：冗長而無效之延遲。測試腳本常因應用程式或環境中之細微異常，而進入長達數分鐘之超時等待狀態，此種情況在敏捷開發之框架下，應被視為不可接受之現象。更甚者，此類測試對於諸如版面配置崩潰、樣式定義錯亂等可由使用者瞬時察覺之重大視覺缺陷，完全不具備感知能力。

此一探索始於對表層問題之處理，然迅速遭遇瓶頸。初代人工智慧助理雖能運用 Playwright 框架之高階除錯工具 (`--ui`)，準確診斷應用程式層級之邏輯謬誤（一項未被模擬之應用程式介面請求），然其最終因一個更為基礎之環境配置問題（`npm install` 指令執行失敗）而致任務中輟。此次失效之經驗，使吾人深刻體認到，任何有效之解決方案，均須具備系統性思維與環境韌性此二要件。

## 策略之形成：人工智慧開發者之崛起

第二次嘗試帶來了方法論上之突破。新一代之人工智慧助理展現了全端診斷之能力，其自後端日誌入手，進行逐層排查，此一過程完美演繹了「建立假設 -> 進行驗證 -> 修正假設」之科學除錯循環。此次之成功，催生了最終策略之核心理念：所追求之目標，不應是一個僅能執行預設指令之「人工智慧助理」，而應是一個具備類人智慧之「人工智慧開發者」。

一套全新之測試典範遂被共同設計出來，其精髓可概括如下：

*   **以「人工智慧視覺巡檢」取代盲目等待**：該程序利用 Playwright 工具快速擷取所有核心介面之視覺快照，並將其與主控台日誌數據相結合，提交予多模態人工智慧模型（如 Gemini）進行批次視覺分析，旨在於數十秒之時間尺度內，完成對整體應用程式之健康狀態掃描。
*   **以「人工智慧根因分析」賦能深度除錯**：當偵測到異常狀態時，系統將自動啟用 Playwright 之 trace 功能，用以收集包含影片紀錄、網路請求、文件物件模型快照在內之多維度數據。人工智慧將對此等「數位事證」進行聚合分析，以提出精準且具可操作性之修復建議。

## 第五章：戰術執行細節：工具鏈與視覺分析工作流

為將我們的戰略願景轉化為可執行的戰術，本章節將深入探討實現「AI 視覺巡檢」與「AI 根因分析」所需的具體工具鏈、替代方案，並以流程圖形式闡明其工作流程。

### 5.1 核心工具鏈與替代方案

我們的策略依賴於一個整合的工具生態系，每個工具各司其職，共同解決特定的痛點。

| 痛點 | 主要工具選擇 | 核心功能與理由 | 備選/輔助工具 |
| :--- | :--- | :--- | :--- |
| 如何自動化瀏覽器操作與數據收集？ | **Playwright** (執行器) | 這是我們整個流程的基石。它負責模擬使用者行為、執行 `page.screenshot()` 進行截圖、透過 `page.on()` 監聽主控台/網路日誌，並在深度除錯時使用 `trace` 功能產生包含所有細節的追蹤檔案。 | **Cypress**: 提供優秀的開發者體驗和視覺化測試介面，但在跨網域和多頁面測試上，Playwright 靈活性更高。 |
| 如何進行精準的視覺比對？ | **多模態 AI (Gemini)** (語意分析) | 我們的核心策略。它不僅僅是像素比對，而是能理解「這個頁面看起來是否正常？」這種語意層級的問題，能發現佈局崩潰等邏輯性視覺錯誤。 | **Percy.io / Applitools**: 這些是專業的「視覺化迴歸測試」工具，擅長進行像素級的精準比對 (Pixel-perfect diffing)。它們可以作為 AI 視覺斷言的補充，用於捕捉細微的、非災難性的 UI 變更（例如按鈕移動了 2 像素）。 |
| 如何聚合與關聯所有日誌？ | **集中式日誌平台** (數據中樞) | 為了讓 AI 進行有效的根因分析，所有數據（前端主控台日誌、後端應用程式日誌、Playwright 測試結果）都應被發送到一個統一的地方。 | **Sentry.io**: 非常適合捕捉前端錯誤，並能與後端日誌關聯。<br>**Datadog**: 提供更全面的可觀測性平台，整合了日誌、指標和 APM。<br>**ELK Stack (自建)**: 提供最大的靈活性，但維護成本較高。 |
| 如何讓測試快速執行？ | **Bun** (加速器) | Bun 作為一個極速的 JavaScript 執行環境和測試執行器 (`bun test`)，能從根本上縮短測試的啟動和執行時間，尤其在 CI/CD 環境中效果顯著。 | **Node.js + pnpm**: pnpm 在依賴安裝速度和磁碟空間管理上，相較於 npm/yarn 也有顯著優勢。 |

### 5.2 AI 視覺分析工作流程設計

我們的核心流程旨在模擬人類開發者的直覺：先快速巡檢，再深度除錯。

1.  **數據收集層 (Data Collection Layer):**
    *   **廣度優先 (Patrol):** 測試腳本執行「AI 視覺巡檢」，快速遍歷所有預定義的核心頁面。在每個頁面，它會同時收集三種數據：① 頁面截圖、② 瀏覽器主控台日誌、③ 失敗的網路請求日誌。
    *   **深度優先 (Drill-down):** 當任何測試失敗時，自動觸發 Playwright 的 `trace` 功能，產生一個包含影片、DOM 快照、網路活動等所有細節的單一追蹤檔案。

2.  **數據分析層 (Analysis Layer):**
    *   所有收集到的數據（無論是巡檢的批量數據，還是單一的追蹤檔案）都會被傳送給一個中央的「AI 分析服務」。
    *   這個服務會根據情境，向多模態 AI 模型提出不同層次的問題。
        *   對於巡檢數據，問題是：「請檢查這批截圖，並結合它們各自的日誌，找出哪些頁面存在視覺異常或功能錯誤。」
        *   對於追蹤檔案，問題是：「這是一個失敗的測試追蹤。請分析所有數據，找出導致測試失敗的根本原因，並提出修復建議。」

3.  **報告與行動層 (Reporting & Action Layer):**
    *   AI 的分析結果會被格式化為一份清晰的報告。
    *   報告會被發送到開發團隊的通訊頻道（如 Slack），或自動在專案管理工具（如 Jira）中建立一個新的 issue，其中包含了失敗的截圖、AI 的分析結論以及建議的修復方向。

### 5.3 流程圖草圖 (Workflow Flowchart)

```
[ CI/CD 觸發 (例如: git push) ]
 |
 V
+---------------------------------+
|      執行測試 (bun test)        |
+---------------------------------+
 |
 V
+---------------------------------+
|   執行「AI 視覺巡檢」戰術        |
| (快速遍歷、截圖、收集日誌)      |
+---------------------------------+
 |
 V
+---------------------------------+
|   所有頁面視覺/功能正常?        |
+-----------------+---------------+
                  |
        +-------+-------+
        |               |
      (是) V           (否) V
+-----------------+ +-------------------------+
| 執行深度功能測試  | |   生成「巡檢失敗報告」    |
+-----------------+ +-------------------------+
        |                       |
        V                       V
+-----------------+ +-------------------------+
| 所有功能測試通過? | |      聚合巡檢數據         |
+---------+-------+ |    (截圖 + 日誌)      |
          |         +-------------------------+
      +---+---+                   |
      |       |                   |
    (是) V   (否) V               |
+-----------+ +---------------------+
| ✅ 測試成功 | | 觸發「AI 根因分析」   |
+-----------+ +---------------------+
                      |
                      |
                      V
+---------------------------------+
|     AI 分析引擎 (Gemini)        |
| (分析巡檢數據或深度追蹤檔案)    |
+---------------------------------+
 |
 V
+---------------------------------+
|       生成詳細分析報告          |
|  (含根因假設與修復建議)         |
+---------------------------------+
 |
 V
+---------------------------------+
|    發送通知 / 建立 Issue        |
+---------------------------------+
 |
 V
+---------------------------------+
|      👨‍💻 開發者介入修復         |
+---------------------------------+
```

## 結論與展望

此次探索之歷程，促使品質保證流程從一種被動、遲緩之狀態，演進至一個主動、迅捷且智慧化之新境界。一個以 Playwright 為執行器、多模態人工智慧為分析核心、Bun 為加速器之黃金技術棧已被確立。未來之目標在於將此套策略完全整合至持續整合與持續部署 (CI/CD) 之流程中，藉此建立一個不僅能發現問題，更能自主診斷、輔助修復之高度自動化開發體系，從而將品質保證之角色，由開發流程之瓶頸，轉化為驅動創新之強大引擎。

---

## 附錄：AI 助理實踐日誌：從環境設定到首次快照

本章節旨在記錄 AI 助理在實際操作中，為達成「啟動本地伺服器並擷取首張UI快照」此一目標所經歷的完整偵錯與解決問題的歷程。這不僅是技術操作的流水帳，更是展現問題解決策略與系統韌性思維的具體實例。

### 初始目標：驗證本地端 UI

任務非常明確：啟動專案的後端伺服器，並透過 Playwright 擷取前端頁面 (`mp3.html`) 的一張螢幕快照，以作為後續所有視覺化測試的基礎。

### 遭遇的挑戰與解決方案

過程並非一帆風順，遭遇了一系列環環相扣的環境與設定問題：

1.  **挑戰一：Python 依賴缺失**
    *   **現象**：首次嘗試啟動伺服器 (`python -m circus.circusd ...`) 時，系統立即報錯 `ModuleNotFoundError: No module named 'circus'`。
    *   **分析**：這是典型的 Python 環境問題，執行的環境中並未安裝必要的依賴套件。
    *   **解決方案**：透過執行 `pip install -r requirements.txt`，將專案所需的所有 Python 套件安裝至當前環境。

2.  **挑戰二：設定檔遺失**
    *   **現象**：解決了依賴問題後，伺服器依然啟動失敗，錯誤訊息轉變為 `OSError: the configuration file 'config/circus.ini' does not exist`。
    *   **分析**：程式碼庫中僅提供了一個範本檔案 `config/circus.ini.template`，而程式預期讀取的是 `config/circus.ini`。
    *   **解決方案**：執行 `cp config/circus.ini.template config/circus.ini`，從範本複製一份正式的設定檔。

3.  **挑戰三：設定檔預留位置未被替換**
    *   **現象**：伺服器日誌中出現了新的錯誤 `[Errno 2] No such file or directory: '%%PYTHON_EXEC%%'`。
    *   **分析**：`circus.ini` 設定檔中使用了一個預留位置 `%%PYTHON_EXEC%%`，它需要被替換為當前環境中 Python 直譯器的確切路徑。
    *   **解決方案**：透過 `which python` 找到 Python 路徑，並使用 `sed` 指令將其寫入設定檔，例如：`sed -i "s|%%PYTHON_EXEC%%|/path/to/python|g" config/circus.ini`。

4.  **挑戰四：Node.js 依賴缺失**
    *   **現象**：在伺服器問題看似解決後，執行 Playwright 測試 (`npx playwright test ...`) 時，出現了前端錯誤 `Error [ERR_MODULE_NOT_FOUND]: Cannot find package '@playwright/test'`。
    *   **分析**：與 Python 類似，Node.js 的環境也需要安裝其專案依賴。
    *   **解決方案**：執行 `npm install`，安裝 `package.json` 中定義的所有開發與執行依賴。

5.  **挑戰五：頑固的連接埠衝突**
    *   **現象**：最令人困惑的問題隨之而來。即使所有設定都已正確，測試仍然頻繁失敗，錯誤為 `net::ERR_CONNECTION_REFUSED`，同時伺服器日誌顯示 `Address already in use`。這表示即使先前的程序已終止，仍有殭屍程序佔用著連接埠。
    *   **分析**：手動管理伺服器啟動與關閉的過程非常不穩定，尤其是在自動化腳本中。
    *   **最終解決方案**：
        1.  **授權給 Playwright**：修改 `playwright.config.js`，加入 `webServer` 設定。這讓 Playwright 自身負責在測試前啟動伺服器、檢查其健康狀態，並在測試結束後關閉它，從根本上解決了手動管理的穩定性問題。
        2.  **確保狀態純淨**：為了解決殭屍程序問題，最終採用了「在執行測試的同一個指令中，先強制清理再啟動」的策略：`pkill -9 -f circus; npx playwright test ...`。這確保了每次執行都是在一個絕對乾淨的狀態下開始。

### 結論：從混亂到穩定

這次實踐充分證明，一個看似簡單的任務，在真實的開發環境中可能因為環境配置、依賴管理和程序狀態等問題而變得複雜。透過系統性的「假設-驗證」循環，並最終採用更穩健的工具（如 Playwright 的 `webServer` 功能），我們成功地建立了一個可靠的自動化測試基礎。這次經驗也被記錄下來，為未來更深入的 AI 視覺分析流程奠定了堅實的基礎。
